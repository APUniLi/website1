{
  "hash": "22621c368ce95b3b9877c09a83b93279",
  "result": {
    "markdown": "---\ntitle: \"Non-standard errors in portfolio sorts\"\nauthor: \"Patrick Weiss\"\ndate: \"2023-05-05\"\ndescription: An easy implementation for NSE in portfolio sorts\ncategories: \n  - Replications\n---\n\n\n# Introduction\n\nI find non-standard errors[^1] very exciting and an important angle on academic research activity generally. Luckily, Stefan Voigt asked me to join forces contributing to Menkveld et al. (2023). Furthermore, if you look back at the history of Tidy Finance, we included a chapter on [Size sorts and p-hacking](https://www.tidy-finance.org/size-sorts-and-p-hacking.html) early, starting an assessment of different choices in portfolio sorts. Recently, my excellent co-authors (shout out to [Dominik Walter](https://sites.google.com/view/dominikwalter/startseite) and [Rüdiger Weber](https://sites.google.com/site/ruedigercweber/)) and I uploaded a new working paper version of \"Non-Standard Errors in Portfolio Sorts\"[^2] (WWW below). In the paper, we thoroughly study how methodological choices influence return differentials estimated from portfolio sorts. The conclusion is that we should embrace non-standard errors and report distributions of return differentials.\n\nThis blog article will teach you how to do portfolio sorts with non-standard errors in mind, i.e., vary over possible decisions to gain a deeper insight into return differentials. We will estimate one premium's distribution as opposed to a single return differential. The code here is inspired by Tidy Finance with R and the replication code for WWW in this [Github repository](https://github.com/patrick-weiss/PortfolioSorts_NSE). In the end, you will know how to sort portfolios on the variable *asset growth* in nearly 70,000 ways.\n\n# Data\n\nFirst, we need some data. On the one hand, we need the monthly return time series for the CRSP universe. On the other hand, we need some accounting data from Compustat for constructing the sorting variable itself. To save space and because there is a chatper in Tidy Finance on it, I refer you to our chapter on [WRDS, CRSP, and Compustat](https://www.tidy-finance.org/wrds-crsp-compustat.html) for the details on how to download the data. Here, I only read the data from my SQLite database.\n\nWe first need a few packages. The `tidyverse` (of course) and the `RSQLite`-package for the database. Additionally, I connect to my database that contains all necessary data. The prefix `../` in the path argument moves one directory up.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Packages\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyverse' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tibble' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'readr' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'purrr' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'stringr' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'forcats' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'lubridate' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ───────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n── Conflicts ─────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(RSQLite)\n\n# Database\n# SQLite database\ndata_tidy_nse <- dbConnect(SQLite(), \n                           \"../../data/data_nse.sqlite\", \n                           extended_types = TRUE)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_monthly <- dbReadTable(data_tidy_nse, \"crsp_monthly\")\ncompustat <- dbReadTable(data_tidy_nse, \"compustat\")\n```\n:::\n\n\nThen, I need to construct the sorting variable. As an example for this post, I decided to use *asset growth*, which was suggested as a predictor of the cross-section of stock prices by Cooper, Gulen, and Schill (2008)[^3]. Asset growth is measured as the relative change in total assets of a firm. Additionally, I compute three *filters* relating to the firm's stock price, book equity, and earnings. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Lag variable\ncompustat_lag <- compustat |> \n  select(gvkey, year, at) |> \n  mutate(year = year + 1) |> \n  rename_with(.cols = at, ~ paste0(.x, \"_lag\"))\n\n# Compute asset growth\ncompustat <- compustat |> \n  left_join(compustat_lag, by = c(\"gvkey\", \"year\")) |> \n  mutate(sv_ag = (at - at_lag) / at_lag)\n\n# Compute filters\ncompustat <- compustat |> \n  mutate(filter_be = coalesce(seq, ceq + pstk, at - lt) + coalesce(txditc, txdb + itcb, 0) - coalesce(pstkrv, pstkl, pstk, 0),\n         filter_price = prcc_f,\n         filter_earnings = ib)\n\n# Select required variables\ncompustat <- compustat |> \n  select(gvkey, month, datadate, starts_with(\"filter_\"), starts_with(\"sv_\"))\n```\n:::\n\n\nFor the crsp data, we also construct a variable that we will need below. We compute the stock age filter as the time in years between the stock's first appearance in CRSP and the current month. To do this reliably, we again leverage `group_by()`'s power. Note that market capitalization is already in the CRSP database, following our main data construction.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_monthly <- crsp_monthly |>\n  group_by(permno) |>\n  arrange(month) |>\n  mutate(filter_stock_age = as.numeric(difftime(month, min(month), units = \"days\"))/365) |> \n  ungroup() |> \n  select(permno, gvkey, month, industry, exchange, mktcap, mktcap_lag, ret_excess, filter_stock_age)\n```\n:::\n\n\nAt the moment, we only have panels of stock returns and characteristics. These panels have not even been matched together yet, because this also constitutes a decision. Hence, let us move to discussing these decisions.\n\n# The decision nodes\n\nIn WWW, we identify 14 methodological choices that have to be made to arrive at an estimate of a premium from portfolio sorts. We split these into decision on the sample construction and the portfolio construction. I provide you a table below and refer you to WWW for details on these nodes.\n\nNode | Choices\n:------|:------\nSize restriction | none, NYSE 5%, NYSE 20%\nFinancials | include, exclude\nUtilities | include, exclude\nPos. book equity | include, exclude\nPos. earnings | include, exclude\nStock-age restriction | none, >2 years\nPrice restriction | none, >\\$1, >\\$5 \nSorting variable lag | 3 months, 6 months, Fama-french\nRebalancing | monthly, annually\nBreapoint quantiles main | 5, 10\nDouble sort | single, double dependent, double independent\nBreapoint quantiles secondary | 2, 5\nBreapoint exchanges | NYSE, all\nWeighting scheme | equal-weighting, value-weighting\n\nIn principle, there are more decisions to be made. However, this set of 14 choices appears in published, peer-reviewed articles and covers different aspects. If you think that another choice is particularly important, I am curious to hearing about it.\n\nLet us now create all possible combinations of choices that are feasible. We use `expand_grid()` on the tibble of individual nodes and their branches. Note that single sorts do not use the node regarding the number of secondary portfolios, i.e., we remove these paths after combining all choices. This leaves us with 69,120 choices.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create sorting grid\nsetup_grid <- expand_grid(sorting_variable = \"sv_at\",\n                          drop_smallNYSE_at = c(0, 0.05, 0.2),\n                          include_financials = c(TRUE, FALSE),\n                          include_utilities = c(TRUE, FALSE),\n                          drop_bookequity = c(TRUE, FALSE),\n                          drop_earnings = c(TRUE, FALSE),\n                          drop_stock_age_at = c(0, 2),\n                          drop_price_at = c(0, 1, 5),\n                          sv_lag = c(\"3m\", \"6m\", \"FF\"),\n                          formation_time = c(\"monthly\", \"FF\"),\n                          n_portfolios_main = c(5, 10),\n                          sorting_method = c(\"single\", \"dbl_ind\", \"dbl_dep\"),\n                          n_portfolios_secondary = c(2, 5),\n                          exchanges = c(\"NYSE\", \"NYSE|NASDAQ|AMEX\"),\n                          value_weighted = c(TRUE, FALSE))\n\n# Remove information on double sorting for univariate sorts\nsetup_grid <- setup_grid |> \n  filter(!(sorting_method == \"single\" & n_portfolios_secondary > 2)) |> \n  mutate(n_portfolios_secondary = case_when(sorting_method == \"single\" ~ NA_real_, \n                                            TRUE ~ n_portfolios_secondary))\n```\n:::\n\n\n## Merge data\n\nOne key decision node is the sorting variable lag. However, merging data is an expensive operation and doing it over and over again is not necessary. Hence, I merge the data together in the three possible lag configurations and store them as separate tibbles. Thereby, I can later reference to the correct table instead of merging the desired output again.\n\n\n::: {.cell}\n\n:::\n\n\n\n\n#  Portfolio sorts\n\nWe are equipped with the necessary data and the set of decisions that we consider. Next, we implement our decisions into actual portfolio sorts. Well. First, we have to define a few functions to make the implementation feasible. Thinking in functions is an important aspect that enables you to accomplish the task set for this blog post. Then, we will apply these functions.\n\n## Functions\n\nI write functions that accomplish specific tasks and then combine them to generate to desired output. Breaking it up into smaller steps makes the whole process more tractable and easier to test.\n\nWe start with selecting the data we want\n\n\n\n\n## Applying the functions\n\nFinally, we have data, decisions, and functions. Surely, we are now ready to implement the portfolio sort, right? Yes! Just let me briefly discuss how the implementation works\n\n\n# The premium distribution\n\nGiven all the estimates for the premium, we can now take a look at their distribution.\n\nYou can immediately see one of the results in WWW: There is a lot of variation depending on the choices you make. However, despite the variation, the premium is always positive. \n\n\n# Conclusion\n\nIn essence, any paper proposing a new predictor usually reports one of the specifications we considered here. Then, they run a few robustness checks, where they vary some of the choices. However, space constraints severely limits the space devoted to these checks. But how about our robustness test here? It is actually over 70,000 robustness tests, if you think about it. However, it is just one graph (maybe two if showing the t-statistics as well), which condenses a lot of information in a digestible way. \n\nOf course, we have not tested the return differentials' time series against some factor model to show that existing factors do not explain the premia. I did not show you this step, because the implementation is just an addition to our existing code.\n\nIf you are interested in learning more about non-standard errors in portfolio sorts, I refer you to WWW. We not only cover many variables there, but also dive much deeper into understanding the variation itself. If you read it, let me know what you think.\n\n\n[^1]: Menkveld, A. J. et al. (2023). “Non-standard Errors”, Journal of Finance (forthcoming). http://dx.doi.org/10.2139/ssrn.3961574\n\n[^2]:  Walter, D., Weber, R., and Weiss, P. (2023). \"Non-Standard Errors in Portfolio Sorts\". [http://dx.doi.org/10.2139/ssrn.4164117](http://dx.doi.org/10.2139/ssrn.4164117)\n\n[^3]: Cooper, M. J., Gulen, H., and Schill, M. J. (2008). \"Asset growth and the cross‐section of stock returns\", The Journal of Finance, 63(4), 1609-1651.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}