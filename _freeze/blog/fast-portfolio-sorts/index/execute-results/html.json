{
  "hash": "cda9e6734a36b424b557cf051fc78cf4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Fast Portfolio Sorts\"\nauthor:\n  - name: Christoph Scheuch\n    url: https://www.tidy-intelligence.com/\ndate: \"2024-06-06\"\ndescription: A benchmark of R approaches for efficient portfolio sorts\ncategories: \n  - R\n  - Portfolio Sorts\n  - data.table\nimage: thumbnail.png\nimage-alt: A winner's podium with three genderless robots celebrating, each holding a trophy. The robots have a sleek, modern design with neutral features. The podium is positioned in a modern office setting with bright colors, contemporary furniture, large windows letting in natural light, and vibrant decor. The first-place robot stands in the center, elevated above the second and third place robots on either side, all expressing joy. Created by DALL-E.\n---\n\n\nIn the world of finance and investment management, working with large datasets containing portfolio holdings is a common task. One crucial operation that often needs to be performed on these datasets is portfolio sorts (e.g., see our chapter on [Univariate Portfolio Sorts](../../r/univariate-portfolio-sorts.qmd). While R offers a variety of approaches through its base functions and popular packages like `dplyr` and `data.table`, the performance of these methods can vary significantly, especially when dealing with large datasets. As a data analyst or portfolio manager, it's essential to understand the trade-offs between different sorting approaches in terms of execution time and memory usage. This blog post aims toshed light on this topic by benchmarking the performance of various sorting methods in R, specifically for the use case of sorting portfolio holdings.\n\nWe'll dive into the following sorting approaches:\n\n- Use the built-in `base` functions that ship with every R installation.\n- Leverage the popular `dplyr` package and workhorse of [Tidy Finance with R](../../r/index.qmd).\n- Explore the powerful `data.table` package and its sorting capabilities.\n- Combine the `dplyr` syntax with `data.table`'s performance through `dtplyr`.\n\nThroughout this blog post, I'll use the following packages. Notably, `bench` is used to create benchmarking results. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(dtplyr)\nlibrary(data.table)\nlibrary(bench)\nlibrary(purrr)\nlibrary(RSQLite)\n```\n:::\n\n\n## Data preparation\n\nFirst, I start by loading the monthly CRSP data from our database (see [WRDS, CRSP, and Compustat](../../r/wrds-crsp-and-compustat.qmd) for details). The dataset has about 3 million rows and contains monthly returns between 1960 and 2023 for about 26,000 stocks. I also make sure that the data comes as a `tibble` for `dplyr`, a `data.frame` for `base`, a `data.table` for `data.table` and a “lazy” data table for `dtplyr` because I want to avoid any conversion issues in the portfolio assignments.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_finance <- dbConnect(\n  SQLite(),\n  \"../../data/tidy_finance_r.sqlite\",\n  extended_types = TRUE\n)\n\ncrsp_monthly_dplyr <- tbl(tidy_finance, \"crsp_monthly\") |>\n  select(permno, month, ret_excess, mktcap_lag) |>\n  collect()\n\ncrsp_monthly_base <- as.data.frame(crsp_monthly_dplyr)\n\ncrsp_monthly_dt <- copy(as.data.table(crsp_monthly_dplyr))\n\ncrsp_monthly_dtplyr <- lazy_dt(crsp_monthly_dplyr)\n```\n:::\n\n\n## Defining portfolio sorts\n\nAs a common denominator across approaches, I introduce a stripped down version of `assign_portfolio()` that can also be found in the [`tidyfinance`](https://cran.r-project.org/web/packages/tidyfinance/index.html) package. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nassign_portfolio <- function(data, sorting_variable, n_portfolios) {\n  \n  breakpoints <- quantile(\n    data[[sorting_variable]], \n    probs = seq(0, 1, length.out = n_portfolios + 1), \n    na.rm = TRUE, names = FALSE\n  )\n\n  findInterval(\n    data[[sorting_variable]], breakpoints, all.inside = TRUE\n  )\n}\n```\n:::\n\n\nThe goal is to apply this function to the cross-section of stocks in each month and then compute average excess returns for each portfolio across all months.  \n\nIf we want to apply the function above to each month using only `base`, then we have to first split the `data.frame` into multiple parts and `lapply()` the function to each part. After we combined the parts again to one big data.frame, we can use `aggregate()` to compute the average excess returns. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsort_base <- function() {\n  df_split <- split(crsp_monthly_base, crsp_monthly_base$month)\n  df_split <- lapply(df_split, function(df) {\n    df$portfolio <- assign_portfolio(df, \"mktcap_lag\", n_portfolios = 10)\n    return(df)\n  })\n  df <- do.call(rbind, df_split)\n  aggregate(ret_excess ~ portfolio, data = df, FUN = function(x) mean(x, na.rm = TRUE))\n}\nsort_base()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   portfolio ret_excess\n1          1    0.02270\n2          2    0.00512\n3          3    0.00482\n4          4    0.00515\n5          5    0.00548\n6          6    0.00608\n7          7    0.00637\n8          8    0.00680\n9          9    0.00647\n10        10    0.00579\n```\n\n\n:::\n:::\n\n\nThis approach takes about 10 seconds per execution on my machine and is in fact more than 20-times slower than the other approaches! To create a more nuanced picture for the fast and arguably more interesting approaches, I'll drop the `base` approach going forward. \n\nIf we want to perform the same logic using `dplyr`, we can use the following approach. Note that I use `as.data.frame()` for all approaches to ensure that the output format is the same for all approaches - a necessary requirement for a meaningful benchmark (otherwise code would not be equivalent).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsort_dplyr <- function() {\n  crsp_monthly_dplyr |> \n    mutate(\n      portfolio = assign_portfolio(\n        pick(everything()), \"mktcap_lag\", n_portfolios = 10),\n      by = \"month\"\n    ) |> \n    group_by(portfolio) |> \n    summarize(ret = mean(ret_excess, na.rm = TRUE)) |> \n    as.data.frame()\n}\nsort_dplyr()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   portfolio     ret\n1          1 0.02351\n2          2 0.00666\n3          3 0.00485\n4          4 0.00455\n5          5 0.00491\n6          6 0.00604\n7          7 0.00656\n8          8 0.00607\n9          9 0.00556\n10        10 0.00607\n```\n\n\n:::\n:::\n\n\nThe equivalent approach in `data.table` looks as follows. Note that I deliberately don't use any pipe or intermediate assignments as to avoid any performance overhead that these might introduce. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsort_dt <- function() {\n  as.data.frame(crsp_monthly_dt[\n    , `:=`(portfolio = assign_portfolio(.SD, \"mktcap_lag\", n_portfolios = 10), by = month)\n    ][, .(ret = mean(ret_excess, na.rm = TRUE)), keyby = .(portfolio)])\n}\nsort_dt()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   portfolio     ret\n1          1 0.02351\n2          2 0.00666\n3          3 0.00485\n4          4 0.00455\n5          5 0.00491\n6          6 0.00604\n7          7 0.00656\n8          8 0.00607\n9          9 0.00556\n10        10 0.00607\n```\n\n\n:::\n:::\n\n\nLastly, I add the `dtplyr` implementation that also takes a `data.table` as input and internally converts `dplyr` code to `data.table` syntax. Note that the final `as.data.frame()` call is used to access the results and ensure that the result format is consistent with the other approaches. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsort_dtplyr <- function() {\n  crsp_monthly_dtplyr |> \n    mutate(\n      portfolio = assign_portfolio(\n        pick(everything()), \"mktcap_lag\", n_portfolios = 10),\n      by = \"month\"\n    )  |> \n    group_by(portfolio) |> \n    summarize(ret = mean(ret_excess, na.rm = TRUE)) |> \n    as.data.frame()\n}\nsort_dtplyr()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   portfolio     ret\n1          1 0.02351\n2          2 0.00666\n3          3 0.00485\n4          4 0.00455\n5          5 0.00491\n6          6 0.00604\n7          7 0.00656\n8          8 0.00607\n9          9 0.00556\n10        10 0.00607\n```\n\n\n:::\n:::\n\n\nNow that we have verified that all code chunks create the same average excess returns per portfolio, we can proceed to the performance evaluation. \n\n## Benchmarking results\n\nThe `bench` package is a great utility for benchmarking and timing expressions in R. It provides functions that allow you to measure the execution time of  expressions or code chunks. This can be useful for comparing the performance of different approaches or implementations, or for identifying potential bottlenecks in your code. The following code evaluates each approach from above a 100 times and collects the results. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\niterations <- 100\n\nresults <- bench::mark(\n  sort_dplyr(), sort_dt(), sort_dtplyr(), \n  iterations = iterations\n)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\nThe following plot shows the distributions of execution times as violin plots. You can see that `data.table` takes the lead and is followed closely by `dbplyr`, while `dtplyr` takes the third place. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nautoplot(results, type = \"violin\") +\n  labs(y = NULL, x = \"Sorting approach\", \n       title = \"Execution time of porfolio sorts using dplyr, data.table, and dtplyr\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=2100}\n:::\n:::\n\n\nNote that all three methods are blazingly fast, given that the task is to assign 10 portfolios across up to 26,000 stocks for 755 months. I personally don't really care for the extra few milliseconds that I'd get through `data.table` by sacrificing the `dplyr` syntax because I code mostly interactively. If your context involves time constraints and needs to be as fast as possible, then you might not only prefer `data.table`, but also thing about more efficient ways to assign portfolios compared to applying the function I have given above. \n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}