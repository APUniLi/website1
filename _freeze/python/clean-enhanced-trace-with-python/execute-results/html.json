{
  "hash": "7ab116ca6d74026b705d914731b5b732",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Clean Enhanced TRACE with Python\nmetadata:\n  pagetitle: Clean Enhanced TRACE with Python\n  description-meta: Copy the code to clean enhanced TRACE bond transaction data using the programming language Python.\n---\n\nThis appendix contains code to clean enhanced TRACE with Python.\\index{Data!TRACE} It is also available via the following Github [gist](https://gist.githubusercontent.com/patrick-weiss/86ddef6de978fbdfb22609a7840b5d8b).\\index{Github!Gist} Hence, you could also source the file with the following chunk.\n\n::: {#3bb3718f .cell execution_count=1}\n``` {.python .cell-code}\ngist_url = (\n  \"https://gist.githubusercontent.com/patrick-weiss/\"\n  \"86ddef6de978fbdfb22609a7840b5d8b/raw/\"\n  \"8fbcc6c6f40f537cd3cd37368be4487d73569c6b/\"\n)\n\nwith httpimport.remote_repo(gist_url):\n  from clean_enhanced_TRACE_python import clean_enhanced_trace\n```\n:::\n\n\nWe need this function in Chapter [TRACE and FISD](trace-and-fisd.qmd) to download and clean enhanced TRACE trade messages following @Dick2009 and @Dick2014 for enhanced TRACE specifically. This code is based on the resources provided by the project [Open Source Bond Asset Pricing](https://openbondassetpricing.com/) and their related publication @Dickerson2023. We encourage that you acknowledge their effort. Related, WRDS provides SAS code to clean enhanced TRACE data.\n\nThe function takes a vector of CUSIPs (in `cusips`), a connection to WRDS (`connection`) explained in Chapter 3, and a start and end date (`start_date` and `end_date`, respectively). Specifying too many CUSIPs will result in very slow downloads and a potential failure due to the size of the request to WRDS. The dates should be within the coverage of TRACE itself, i.e., starting after 2002, and the dates should be supplied as a string indicating MM/DD/YYYY. The output of the function contains all valid trade messages for the selected CUSIPs over the specified period.\\index{CUSIP}\\index{Dick-Nielsen cleaning} \n\n::: {#07dd83a5 .cell execution_count=2}\n``` {.python .cell-code}\ndef clean_enhanced_trace(cusips, \n                         connection, \n                         start_date=\"'01/01/2002'\", \n                         end_date=\"'12/31/2023'\"):\n  \"\"\"Clean enhanced TRACE data.\"\"\"\n  \n  import pandas as pd\n  import numpy as np\n  \n  # Load main file\n  trace_query = (\n    \"SELECT cusip_id, bond_sym_id, trd_exctn_dt, \"\n           \"trd_exctn_tm, days_to_sttl_ct, lckd_in_ind, \"\n           \"wis_fl, sale_cndtn_cd, msg_seq_nb, \"\n           \"trc_st, trd_rpt_dt, trd_rpt_tm, \"\n           \"entrd_vol_qt, rptd_pr, yld_pt, \" \n           \"asof_cd, orig_msg_seq_nb, rpt_side_cd, \"\n           \"cntra_mp_id, stlmnt_dt, spcl_trd_fl \" \n    \"FROM trace.trace_enhanced \" \n   f\"WHERE cusip_id IN {cusips} \" \n         f\"AND trd_exctn_dt BETWEEN {start_date} AND {end_date}â€š\"\n  )\n\n  trace_all = pd.read_sql_query(\n    sql=trace_query,\n    con=connection,\n    parse_dates={\"trd_exctn_dt\",\"trd_rpt_dt\", \"stlmnt_dt\"}\n  )\n  \n  # Post 2012-06-02\n  ## Trades (trc_st = T) and correction (trc_st = R)\n  trace_post_TR = (trace_all\n    .query(\"trc_st in ['T', 'R']\")\n    .query(\"trd_rpt_dt >= '2012-06-02'\")\n  )\n  \n  # Cancellations (trc_st = X) and correction cancellations (trc_st = C)\n  trace_post_XC = (trace_all\n    .query(\"trc_st in ['X', 'C']\")\n    .query(\"trd_rpt_dt >= '2012-06-02'\")\n    .get([\"cusip_id\", \"msg_seq_nb\", \"entrd_vol_qt\",\n          \"rptd_pr\", \"rpt_side_cd\", \"cntra_mp_id\",\n          \"trd_exctn_dt\", \"trd_exctn_tm\"])\n    .assign(drop=True)\n  )\n  \n  ## Cleaning corrected and cancelled trades\n  trace_post_TR = (trace_post_TR\n    .merge(trace_post_XC, how=\"left\")\n    .query(\"drop != True\")\n    .drop(columns=\"drop\")\n  )\n  \n  # Reversals (trc_st = Y) \n  trace_post_Y = (trace_all\n    .query(\"trc_st == 'Y'\")\n    .query(\"trd_rpt_dt >= '2012-06-02'\")\n    .get([\"cusip_id\", \"orig_msg_seq_nb\", \"entrd_vol_qt\",\n          \"rptd_pr\", \"rpt_side_cd\", \"cntra_mp_id\",\n          \"trd_exctn_dt\", \"trd_exctn_tm\"])\n    .assign(drop=True)\n    .rename(columns={\"orig_msg_seq_nb\": \"msg_seq_nb\"})\n  )\n  \n  # Clean reversals\n  ## Match the orig_msg_seq_nb of Y-message to msg_seq_nb of main message\n  trace_post = (trace_post_TR\n    .merge(trace_post_Y, how=\"left\")\n    .query(\"drop != True\")\n    .drop(columns=\"drop\")\n  )\n  \n  # Pre 06-02-12\n  ## Trades (trc_st = T)\n  trace_pre_T = (trace_all\n    .query(\"trd_rpt_dt < '2012-06-02'\")\n  )\n    \n  # Cancelations (trc_st = C) \n  trace_pre_C = (trace_all\n    .query(\"trc_st == 'C'\")\n    .query(\"trd_rpt_dt < '2012-06-02'\")\n    .get([\"cusip_id\", \"orig_msg_seq_nb\", \"entrd_vol_qt\",\n          \"rptd_pr\", \"rpt_side_cd\", \"cntra_mp_id\",\n          \"trd_exctn_dt\", \"trd_exctn_tm\"])\n    .assign(drop=True)\n    .rename(columns={\"orig_msg_seq_nb\": \"msg_seq_nb\"})\n  )\n  \n  # Remove cancellations from trades\n  ## Match orig_msg_seq_nb of C-message to msg_seq_nb of main message\n  trace_pre_T = (trace_pre_T\n    .merge(trace_pre_C, how=\"left\")\n    .query(\"drop != True\")\n    .drop(columns=\"drop\")\n  )\n  \n  # Corrections (trc_st = W)\n  trace_pre_W = (trace_all\n    .query(\"trc_st == 'W'\")\n    .query(\"trd_rpt_dt < '2012-06-02'\")\n  )\n  \n  # Implement corrections in a loop\n  ## Correction control\n  correction_control = len(trace_pre_W)\n  correction_control_last = len(trace_pre_W)\n\n  ## Correction loop\n  while (correction_control > 0):\n    # Create placeholder\n    ## Only identifying columns of trace_pre_T (for joins)\n    placeholder_trace_pre_T = (trace_pre_T\n      .get([\"cusip_id\", \"trd_exctn_dt\", \"msg_seq_nb\"])\n      .rename(columns={\"msg_seq_nb\": \"orig_msg_seq_nb\"})\n      .assign(matched_T=True)\n    )\n    \n    # Corrections that correct some msg\n    trace_pre_W_correcting = (trace_pre_W\n      .merge(placeholder_trace_pre_T, how=\"left\")\n      .query(\"matched_T == True\")\n      .drop(columns=\"matched_T\")\n    )\n\n    # Corrections that do not correct some msg\n    trace_pre_W = (trace_pre_W\n      .merge(placeholder_trace_pre_T, how=\"left\")\n      .query(\"matched_T != True\")\n      .drop(columns=\"matched_T\")\n    )\n    \n    # Create placeholder \n    ## Only identifying columns of trace_pre_W_correcting (for anti-joins)\n    placeholder_trace_pre_W_correcting = (trace_pre_W_correcting\n      .get([\"cusip_id\", \"trd_exctn_dt\", \"orig_msg_seq_nb\"])\n      .rename(columns={\"orig_msg_seq_nb\": \"msg_seq_nb\"})\n      .assign(corrected=True)\n    )\n    \n    # Delete msgs that are corrected \n    trace_pre_T = (trace_pre_T\n      .merge(placeholder_trace_pre_W_correcting, how=\"left\")\n      .query(\"corrected != True\")\n      .drop(columns=\"corrected\")\n    )\n    \n    # Add correction msgs\n    trace_pre_T = pd.concat([trace_pre_T, trace_pre_W_correcting])\n\n    # Escape if no corrections remain or they cannot be matched\n    correction_control = len(trace_pre_W)\n    \n    if correction_control == correction_control_last: \n      break\n    else:\n      correction_control_last = len(trace_pre_W)\n      continue\n  \n  # Reversals (asof_cd = R)\n  ## Record reversals\n  trace_pre_R = (trace_pre_T\n    .query(\"asof_cd == 'R'\")\n    .sort_values([\"cusip_id\", \"trd_exctn_dt\",\n                 \"trd_exctn_tm\", \"trd_rpt_dt\", \"trd_rpt_tm\"])\n  )\n  \n  ## Prepare final data\n  trace_pre = (trace_pre_T\n    .query(\n      \"asof_cd == None | asof_cd.isnull() | asof_cd not in ['R', 'X', 'D']\"\n    )\n    .sort_values([\"cusip_id\", \"trd_exctn_dt\",\n                 \"trd_exctn_tm\", \"trd_rpt_dt\", \"trd_rpt_tm\"])\n  )\n  \n  ## Add grouped row numbers\n  trace_pre_R[\"seq\"] = (trace_pre_R\n    .groupby([\"cusip_id\", \"trd_exctn_dt\", \"entrd_vol_qt\",\n              \"rptd_pr\", \"rpt_side_cd\", \"cntra_mp_id\"])\n    .cumcount()\n  )\n\n  trace_pre[\"seq\"] = (trace_pre\n    .groupby([\"cusip_id\", \"trd_exctn_dt\", \"entrd_vol_qt\",\n              \"rptd_pr\", \"rpt_side_cd\", \"cntra_mp_id\"])\n    .cumcount()\n  )\n  \n  ## Select columns for reversal cleaning\n  trace_pre_R = (trace_pre_R\n    .get([\"cusip_id\", \"trd_exctn_dt\", \"entrd_vol_qt\",\n         \"rptd_pr\", \"rpt_side_cd\", \"cntra_mp_id\", \"seq\"])\n    .assign(reversal=True)\n  )\n  \n  ## Remove reversals and the reversed trade\n  trace_pre = (trace_pre\n    .merge(trace_pre_R, how=\"left\")\n    .query(\"reversal != True\")\n    .drop(columns=[\"reversal\", \"seq\"])\n  )\n  \n  # Agency trades\n  # Combine pre and post trades\n  trace_clean = pd.concat([trace_pre, trace_post])\n  \n  # Keep agency sells and unmatched agency buys\n  ## Agency sells\n  trace_agency_sells = (trace_clean \n    .query(\"cntra_mp_id == 'D' & rpt_side_cd == 'S'\")\n  )\n  \n  # Placeholder for trace_agency_sells with relevant columns\n  placeholder_trace_agency_sells = (trace_agency_sells\n    .get([\"cusip_id\", \"trd_exctn_dt\",\n          \"entrd_vol_qt\", \"rptd_pr\"])\n    .assign(matched=True)\n  )\n\n  # Agency buys that are unmatched\n  trace_agency_buys_filtered = (trace_clean  \n    .query(\"cntra_mp_id == 'D' & rpt_side_cd == 'B'\")\n    .merge(placeholder_trace_agency_sells, how=\"left\")\n    .query(\"matched != True\")\n    .drop(columns=\"matched\")\n  )\n  \n  # Non-agency\n  trace_nonagency = (trace_clean \n    .query(\"cntra_mp_id == 'C'\")\n  )\n  \n  # Agency cleaned\n  trace_clean = pd.concat([trace_nonagency, \n                           trace_agency_sells, \n                           trace_agency_buys_filtered])\n  \n  # Additional Filters\n  trace_add_filters = (trace_clean\n    .assign(\n      days_to_sttl_ct2 = lambda x: (\n        (x[\"stlmnt_dt\"]-x[\"trd_exctn_dt\"]).dt.days\n      )\n    )\n    .assign(\n      days_to_sttl_ct = lambda x: pd.to_numeric(\n        x[\"days_to_sttl_ct\"], errors='coerce'\n      )\n    )\n    .query(\"days_to_sttl_ct.isnull() | days_to_sttl_ct <= 7\")\n    .query(\"days_to_sttl_ct2.isnull() | days_to_sttl_ct2 <= 7\")\n    .query(\"wis_fl == 'N'\")\n    .query(\"spcl_trd_fl.isnull() | spcl_trd_fl == ''\")\n    .query(\"asof_cd.isnull() | asof_cd == ''\")\n  )\n  \n  # Output\n  # Only keep necessary columns\n  trace_final = (trace_add_filters\n    .sort_values([\"cusip_id\", \"trd_exctn_dt\", \"trd_exctn_tm\"])\n    .get([\"cusip_id\", \"trd_exctn_dt\", \"trd_exctn_tm\", \"rptd_pr\", \n          \"entrd_vol_qt\", \"yld_pt\", \"rpt_side_cd\", \"cntra_mp_id\"])\n  )\n  \n  return trace_final\n```\n:::\n\n\n",
    "supporting": [
      "clean-enhanced-trace-with-python_files"
    ],
    "filters": [],
    "includes": {}
  }
}