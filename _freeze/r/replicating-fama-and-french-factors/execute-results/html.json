{
  "hash": "e9c925ba3327da48ce670923883ed3ad",
  "result": {
    "markdown": "---\ntitle: Replicating Fama and French Factors\naliases:\n  - ../replicating-fama-and-french-factors.html\n---\n\n\nIn this chapter, we provide a replication of the famous five Fama and French factor portfolios. The Fama and French factor models are a cornerstone of empirical asset pricing [see @Fama1992 and @FamaFrench2015]. On top of the market factor represented by the traditional CAPM beta, the model includes the size, value, profitability and investment factors to explain the cross section of returns. We introduced the size and value factors in Chapter 9, and their definition remains the same. Size is the SMB factor (small-minus-big) that is long small firms and short large firms. The value factor is HML (high-minus-low) and is long in high book-to-market firms and short in low book-to-market counterparts. We extend these definitions by the profitability factor RMW (robust-minus-weak) as the difference between the returns of firms with high and low operating profitability and the investment factor CMA (conservative-minus-aggressive) as the difference between firms with high versus low investment rates. \n\nThe current chapter relies on this set of packages. \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(RSQLite)\n```\n:::\n\n\n## Data Preparation\n\nWe use CRSP and Compustat as data sources, as we need the same variables to compute the factors in the way Fama and French do it. Hence, there is nothing new below and we only load data from our `SQLite`-database introduced in Chapters 2-4.\\index{Data!CRSP}\\index{Data!Compustat}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_finance <- dbConnect(\n  SQLite(),\n  \"data/tidy_finance.sqlite\",\n  extended_types = TRUE\n)\n\ncrsp_monthly <- tbl(tidy_finance, \"crsp_monthly\") |>\n  select(\n    permno, gvkey, month, ret_excess,\n    mktcap, mktcap_lag, exchange\n  ) |>\n  collect() |>\n  drop_na()\n\ncompustat <- tbl(tidy_finance, \"compustat\") |>\n    select(gvkey, datadate, be, op, inv) |>\n    collect() |>\n    drop_na()\n\nfactors_ff_monthly <- tbl(tidy_finance, \"factors_ff_monthly\") |>\n  select(month, smb, hml, rmw, cma) |>\n  collect()\n```\n:::\n\n\nYet when we start merging our data set for computing the premiums, there are a few differences to Chapter 9. First, Fama and French form their portfolios in June of year $t$, whereby the returns of July are the first monthly return for the respective portfolio. For firm size, they consequently use the market capitalization recorded for June. It is then held constant until June of year $t+1$.\n\nSecond, Fama and French also have a different protocol for computing the book-to-market ratio.\\index{Book-to-market ratio} They use market equity as of the end of year $t - 1$ and the book equity reported in year $t-1$, i.e., the `datadate` is within the last year.\\index{Book equity} Hence, the book-to-market ratio can be based on accounting information that is up to 18 months old. Market equity also does not necessarily reflect the same time point as book equity. The other sorting variables are analogously to book equity taken from year  $t-1$.\n\nTo implement all these time lags, we again employ the temporary `sorting_date`-column. Notice that when we combine the information, we want to have a single observation per year and stock since we are only interested in computing the breakpoints held constant for the entire year. We ensure this by a call of `distinct()` at the end of the chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsize <- crsp_monthly |>\n  filter(month(month) == 6) |>\n  mutate(sorting_date = month %m+% months(1)) |>\n  select(permno, exchange, sorting_date, size = mktcap)\n\nmarket_equity <- crsp_monthly |>\n  filter(month(month) == 12) |>\n  mutate(sorting_date = ymd(str_c(year(month) + 1, \"0701)\"))) |>\n  select(permno, gvkey, sorting_date, me = mktcap)\n\nother_sorting_variables <- compustat |>\n  mutate(sorting_date = ymd(str_c(year(datadate) + 1, \"0701\"))) |>\n  select(gvkey, sorting_date, be, op, inv) |>\n  inner_join(market_equity, by = c(\"gvkey\", \"sorting_date\")) |>\n  mutate(bm = be / me) |>\n  select(permno, sorting_date, me, be, bm, op, inv)\n\nsorting_variables <- size |>\n  inner_join(\n    other_sorting_variables, by = c(\"permno\", \"sorting_date\")\n    ) |>\n  drop_na() |>\n  distinct(permno, sorting_date, .keep_all = TRUE)\n```\n:::\n\n\n## Portfolio Sorts\n\nNext, we construct our portfolios with an adjusted `assign_portfolio()` function.\\index{Portfolio sorts} Fama and French rely on NYSE-specific breakpoints, they form two portfolios in the size dimension at the median and three portfolios in the dimension of each other sorting variable at the 30%- and 70%-percentiles, and they use dependent sorts. The sorts for book-to-market require an adjustment to the function in Chapter 9 because the `seq()` we would produce does not produce the right breakpoints. Instead of `n_portfolios`, we now specify `percentiles`, which take the breakpoint-sequence as an object specified in the function's call. Specifically, we give `percentiles = c(0, 0.3, 0.7, 1)` to the function. Additionally, we perform an `inner_join()` with our return data to ensure that we only use traded stocks when computing the breakpoints as a first step.\\index{Breakpoints}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nassign_portfolio <- function(data, \n                             sorting_variable, \n                             percentiles) {\n  breakpoints <- data |>\n    filter(exchange == \"NYSE\") |>\n    pull({{ sorting_variable }}) |>\n    quantile(\n      probs = percentiles,\n      na.rm = TRUE,\n      names = FALSE\n    )\n\n  assigned_portfolios <- data |>\n    mutate(portfolio = findInterval(\n      pick(everything()) |>\n        pull({{ sorting_variable }}),\n      breakpoints,\n      all.inside = TRUE\n    )) |>\n    pull(portfolio)\n  \n  return(assigned_portfolios)\n}\n\nportfolios <- sorting_variables |>\n  group_by(sorting_date) |>\n  mutate(\n    portfolio_size = assign_portfolio(\n      data = pick(everything()),\n      sorting_variable = size,\n      percentiles = c(0, 0.5, 1)\n    )) |> \n  group_by(sorting_date, portfolio_size) |> \n  mutate(\n    across(c(bm, op, inv), ~assign_portfolio(\n      data = pick(everything()), \n      sorting_variable = ., \n      percentiles = c(0, 0.3, 0.7, 1)),\n      .names = \"portfolio_{.col}\"\n    )\n  ) |>\n  ungroup() |> \n  select(permno, sorting_date, \n         portfolio_size, portfolio_bm,\n         portfolio_op, portfolio_inv)\n```\n:::\n\n\nNext, we merge the portfolios to the return data for the rest of the year. To implement this step, we create a new column `sorting_date` in our return data by setting the date to sort on to July of $t-1$ if the month is June (of year $t$) or earlier or to July of year $t$ if the month is July or later.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nportfolios <- crsp_monthly |>\n  mutate(sorting_date = case_when(\n    month(month) <= 6 ~ ymd(str_c(year(month) - 1, \"0701\")),\n    month(month) >= 7 ~ ymd(str_c(year(month), \"0701\"))\n  )) |>\n  inner_join(portfolios, by = c(\"permno\", \"sorting_date\"))\n```\n:::\n\n\n## Fama and French Factor Returns\n\nEquipped with the return data and the assigned portfolios, we can now compute the value-weighted average return for each of the  portfolios. Then, we form the Fama and French factors. For the size factor (i.e., SMB), we go long in the three small portfolios and short the three large portfolios by taking an average across either group. For the value factor (i.e., HML), we go long in the two high book-to-market portfolios and short the two low book-to-market portfolios, again weighting them equally. For the profitability factor (i.e., RMW), we take a long position in the two high profitability portfolios and a short position in the two low profitability poertfolios. Finally, for the investment factor (i.e., CMA), we go long the two low investment portfolios and short the two high investment portfolios. \\index{Factor!Size factor}\\index{Factor!Value}\\index{Factor!Profitability}\\index{Factor!Investment}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactors_size <- portfolios |>\n  group_by(portfolio_size, month) |>\n  summarize(\n    ret = weighted.mean(ret_excess, mktcap_lag), .groups = \"drop\"\n  ) |>\n  group_by(month) |>\n  summarize(\n    smb_replicated = mean(ret[portfolio_size == 1]) -\n      mean(ret[portfolio_size == 2])\n  )\n\nfactors_book_to_market <- portfolios |>\n  group_by(portfolio_size, portfolio_bm, month) |>\n  summarize(\n    ret = weighted.mean(ret_excess, mktcap_lag), .groups = \"drop\"\n  ) |>\n  group_by(month) |>\n  summarize(\n    hml_replicated = mean(ret[portfolio_bm == 3]) -\n      mean(ret[portfolio_bm == 1])\n  )\n\nfactors_profitability <- portfolios |>\n  group_by(portfolio_size, portfolio_op, month) |>\n  summarize(\n    ret = weighted.mean(ret_excess, mktcap_lag), .groups = \"drop\"\n  ) |>\n  group_by(month) |>\n  summarize(\n    rmw_replicated = mean(ret[portfolio_op == 3]) -\n      mean(ret[portfolio_op == 1])\n  )\n\nfactors_investment <- portfolios |>\n  group_by(portfolio_size, portfolio_inv, month) |>\n  summarize(\n    ret = weighted.mean(ret_excess, mktcap_lag), .groups = \"drop\"\n  ) |>\n  group_by(month) |>\n  summarize(\n    cma_replicated = mean(ret[portfolio_inv == 1]) -\n      mean(ret[portfolio_inv == 3])\n  )\n\nfactors <- factors_size |> \n  full_join(\n    factors_book_to_market, by = \"month\"\n  ) |> \n  full_join(\n    factors_profitability, by = \"month\"\n  ) |> \n  full_join(\n    factors_investment, by = \"month\"\n  )\n```\n:::\n\n\n## Replication Evaluation\n\nIn the previous section, we replicated the size, value, profitability, and investment premiums following the procedure outlined by Fama and French.\\index{Size!Size premium}\\index{Value premium}\\index{Profitability premium}\\index{Investment premium} The final question is then: how close did we get? We answer this question by looking at the two time-series estimates in a regression analysis using `lm()`. If we did a good job, then we should see a non-significant intercept (rejecting the notion of systematic error), a coefficient close to 1 (indicating a high correlation), and an adjusted R-squared close to 1 (indicating a high proportion of explained variance).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- factors_ff_monthly |>\n  inner_join(factors, by = \"month\") |>\n  mutate(\n    across(c(smb_replicated, hml_replicated,\n             rmw_replicated, cma_replicated), ~round(., 4))\n  )\n```\n:::\n\n\nThe results for the SMB factor are quite convincing as all three criteria outlined above are met and the coefficient is around 0.95 and R-squared is at 98%. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(smb ~ smb_replicated, data = test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = smb ~ smb_replicated, data = test)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.022181 -0.002197  0.000025  0.002129  0.017469 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    9.52e-05   1.59e-04     0.6     0.55    \nsmb_replicated 9.45e-01   4.99e-03   189.1   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0042 on 700 degrees of freedom\nMultiple R-squared:  0.981,\tAdjusted R-squared:  0.981 \nF-statistic: 3.58e+04 on 1 and 700 DF,  p-value: <2e-16\n```\n:::\n:::\n\n\nThe replication of the HML factor is also a success, although at a slightly higher coefficient of 0.99 and R-squared around 93%. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(hml ~ hml_replicated, data = test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = hml ~ hml_replicated, data = test)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.04444 -0.00409 -0.00030  0.00416  0.03671 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    0.000477   0.000300    1.59     0.11    \nhml_replicated 0.988879   0.010607   93.23   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.00793 on 700 degrees of freedom\nMultiple R-squared:  0.925,\tAdjusted R-squared:  0.925 \nF-statistic: 8.69e+03 on 1 and 700 DF,  p-value: <2e-16\n```\n:::\n:::\n\n\nWe are also able to replicate the RMW factor quite well with a coefficient of 0.96 and an R-squared of 94%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(rmw ~ rmw_replicated, data = test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = rmw ~ rmw_replicated, data = test)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.019844 -0.003084  0.000133  0.003369  0.018769 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    8.62e-05   2.05e-04    0.42     0.67    \nrmw_replicated 9.55e-01   9.06e-03  105.33   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.00539 on 700 degrees of freedom\nMultiple R-squared:  0.941,\tAdjusted R-squared:  0.941 \nF-statistic: 1.11e+04 on 1 and 700 DF,  p-value: <2e-16\n```\n:::\n:::\n\n\nFinally, the CMA factor also replicates well with a coefficient of 0.97 and an R-squared of 95%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(cma ~ cma_replicated, data = test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = cma ~ cma_replicated, data = test)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.015137 -0.002776 -0.000209  0.002452  0.021725 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    0.000738   0.000173    4.27  2.2e-05 ***\ncma_replicated 0.965387   0.008599  112.27  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.00455 on 700 degrees of freedom\nMultiple R-squared:  0.947,\tAdjusted R-squared:  0.947 \nF-statistic: 1.26e+04 on 1 and 700 DF,  p-value: <2e-16\n```\n:::\n:::\n\n\nThe evidence hence allows us to conclude that we did a relatively good job in replicating the original Fama-French premiums, although we cannot see their underlying code. \nFrom our perspective, a perfect match is only possible with additional information from the maintainers of the original data. \n\n## Exercises\n\n1. @Fama1993 claim that their sample excludes firms until they have appeared in Compustat for two years. Implement this additional filter and compare the improvements of your replication effort. \n2. On his homepage, [Kenneth French](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/variable_definitions.html) provides instructions on how to construct the most common variables used for portfolio sorts. Pick one of them, e.g. `OP` (operating profitability) and try to replicate the portfolio sort return time series provided on his homepage.  \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}