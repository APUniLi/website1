{
  "hash": "3c343cfb55b4ef6f1450752ae1b1d75e",
  "result": {
    "markdown": "---\ntitle: Beta Estimation\naliases:\n  - ../beta-estimation.html\n---\n\n\nIn this chapter, we introduce an important concept in financial economics: the exposure of an individual stock to changes in the market portfolio. According to the Capital Asset Pricing Model (CAPM) of @Sharpe1964, @Lintner1965, and @Mossin1966, cross-sectional variation in expected asset returns should be a function of the covariance between the excess return of the asset and the excess return on the market portfolio.\\index{CAPM} The regression coefficient of excess market returns on excess stock returns is usually called the market beta. We show an estimation procedure for the market betas.\\index{Beta} We do not go into details about the foundations of market beta but simply refer to any treatment of the [CAPM](https://en.wikipedia.org/wiki/Capital_asset_pricing_model) for further information. Instead, we provide details about all the functions that we use to compute the results. In particular, we leverage useful computational concepts: rolling-window estimation and parallelization.\n\nWe use the following packages throughout this chapter:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(RSQLite)\nlibrary(scales)\nlibrary(slider)\nlibrary(furrr)\n```\n:::\n\n\nCompared to previous chapters, we introduce `slider` [@slider] for sliding window functions, and `furrr` [@furrr] to apply mapping functions in parallel.\n\n## Estimating Beta using Monthly Returns\n\nThe estimation procedure is based on a rolling-window estimation, where we may use either monthly or daily returns and different window lengths. First, let us start with loading the monthly CRSP data from our `SQLite`-database introduced in the previous Chapters 2-4.\\index{Data!CRSP}\\index{Data!Fama-French factors}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_finance <- dbConnect(\n  SQLite(),\n  \"data/tidy_finance.sqlite\",\n  extended_types = TRUE\n)\n\ncrsp_monthly <- tbl(tidy_finance, \"crsp_monthly\") |>\n  select(permno, month, industry, ret_excess) |>\n  collect()\n\nfactors_ff5_monthly <- tbl(tidy_finance, \"factors_ff5_monthly\") |>\n  select(month, mkt_excess) |>\n  collect()\n\ncrsp_monthly <- crsp_monthly |>\n  left_join(factors_ff5_monthly, by = \"month\")\n```\n:::\n\n\nTo estimate the CAPM regression coefficients  \n$$\nr_{i, t} - r_{f, t} = \\alpha_i + \\beta_i(r_{m, t}-r_{f,t})+\\varepsilon_{i, t}\n$$\nwe regress stock excess returns `ret_excess` on excess returns of the market portfolio `mkt_excess`. \nR provides a simple solution to estimate (linear) models with the function `lm()`. `lm()` requires a formula as input that is specified in a compact symbolic form. An expression of the form `y ~ model` is interpreted as a specification that the response `y` is modeled by a linear predictor specified symbolically by `model`. Such a model consists of a series of terms separated by `+` operators. In addition to standard linear models, `lm()` provides a lot of flexibility. You should check out the documentation for more information. To start, we restrict the data only to the time series of observations in CRSP that correspond to Apple’s stock (i.e., to `permno` 14593 for Apple) and compute $\\hat\\alpha_i$ as well as $\\hat\\beta_i$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- lm(ret_excess ~ mkt_excess,\n  data = crsp_monthly |>\n    filter(permno == \"14593\")\n)\n\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = ret_excess ~ mkt_excess, data = filter(crsp_monthly, \n    permno == \"14593\"))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5170 -0.0589  0.0001  0.0610  0.3947 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.01019    0.00508     2.0    0.046 *  \nmkt_excess   1.38889    0.11141    12.5   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.113 on 502 degrees of freedom\nMultiple R-squared:  0.236,\tAdjusted R-squared:  0.235 \nF-statistic:  155 on 1 and 502 DF,  p-value: <2e-16\n```\n:::\n:::\n\n\n`lm()` returns an object of class `lm` which contains all information we usually care about with linear models. `summary()` returns an overview of the estimated parameters. `coefficients(fit)` would return only the estimated coefficients. The output above indicates that Apple moves excessively with the market as the estimated $\\hat\\beta_i$ is above one ($\\hat\\beta_i \\approx 1.4$). \n\n## Rolling-Window Estimation\n\nAfter we estimated the regression coefficients on an example, we scale the estimation of  $\\beta_i$ to a whole different level and perform rolling-window estimations for the entire CRSP sample.\\index{Rolling-window estimation} The following function implements the CAPM regression for a data frame (or a part thereof) containing at least `min_obs` observations to avoid huge fluctuations if the time series is too short. If the condition is violated, that is, the time series is too short, the function returns a missing value. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate_capm <- function(data, min_obs = 1) {\n  if (nrow(data) < min_obs) {\n    beta <- as.numeric(NA)\n  } else {\n    fit <- lm(ret_excess ~ mkt_excess, data = data)\n    beta <- as.numeric(coefficients(fit)[2])\n  }\n  return(beta)\n}\n```\n:::\n\n\nNext, we define a function that does the rolling estimation. The `slide_period` function is able to handle months in its window input in a straightforward manner. We thus avoid using any time-series package (e.g., `zoo`) and converting the data to fit the package functions, but rather stay in the world of the `tidyverse`.\n\nThe following function takes input data and slides across the `month` vector, considering only a total of `months` months. The function essentially performs three steps: (i) arrange all rows, (ii) compute betas by sliding across months, and (iii) return a tibble with months and corresponding beta estimates (again particularly useful in the case of daily data).\nAs we demonstrate further below, we can also apply the same function to daily returns data. \n\n::: {.cell}\n\n```{.r .cell-code}\nroll_capm_estimation <- function(data, months, min_obs) {\n  data <- data |>\n    arrange(month)\n\n  betas <- slide_period_vec(\n    .x = data,\n    .i = data$month,\n    .period = \"month\",\n    .f = ~ estimate_capm(., min_obs),\n    .before = months - 1,\n    .complete = FALSE\n  )\n\n  return(tibble(\n    month = unique(data$month),\n    beta = betas\n  ))\n}\n```\n:::\n\n\nBefore we attack the whole CRSP sample, let us focus on a couple of examples for well-known firms.\n\n::: {.cell}\n\n```{.r .cell-code}\nexamples <- tribble(\n  ~permno, ~company,\n  14593, \"Apple\",\n  10107, \"Microsoft\",\n  93436, \"Tesla\",\n  17778, \"Berkshire Hathaway\"\n)\n```\n:::\n\nIf we want to estimate rolling betas for Apple, we can use `mutate()`. \nWe take a total of 5 years of data and require at least 48 months with return data to compute our betas. \nCheck out the exercises if you want ot compute beta for different time periods. \n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_example <- crsp_monthly |>\n  filter(permno == examples$permno[1]) |>\n  mutate(roll_capm_estimation(pick(everything()), months = 60, min_obs = 48)) |>\n  drop_na()\nbeta_example\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 457 × 6\n  permno month      industry      ret_excess mkt_excess  beta\n   <dbl> <date>     <chr>              <dbl>      <dbl> <dbl>\n1  14593 1984-12-01 Manufacturing     0.170      0.0184  2.05\n2  14593 1985-01-01 Manufacturing    -0.0108     0.0799  1.90\n3  14593 1985-02-01 Manufacturing    -0.152      0.0122  1.88\n4  14593 1985-03-01 Manufacturing    -0.112     -0.0084  1.89\n5  14593 1985-04-01 Manufacturing    -0.0467    -0.0096  1.90\n# ℹ 452 more rows\n```\n:::\n:::\n\nIt is actually quite simple to perform the rolling-window estimation for an arbitrary number of stocks, which we visualize in the following code chunk and the resulting @fig-601. \n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_examples <- crsp_monthly |>\n  inner_join(examples, by = \"permno\") |>\n  group_by(permno) |>\n  mutate(roll_capm_estimation(pick(everything()), months = 60, min_obs = 48)) |>\n  ungroup() |>\n  select(permno, company, month, beta) |>\n  drop_na()\n\nbeta_examples |>\n  ggplot(aes(\n    x = month, \n    y = beta, \n    color = company,\n    linetype = company)) +\n  geom_line() +\n  labs(\n    x = NULL, y = NULL, color = NULL, linetype = NULL,\n    title = \"Monthly beta estimates for example stocks using 5 years of data\"\n  )\n```\n\n::: {.cell-output-display}\n![The CAPM betas are estimated with monthly data and a rolling window of length 5 years based on adjusted excess returns from CRSP. We use market excess returns from Kenneth French data library.](beta-estimation_files/figure-html/fig-601-1.png){#fig-601 fig-alt='Title: Monthly beta estimates for example stocks using 5 years of data. The figure shows a time series of beta estimates based on 5 years of monthly data for Apple, Berkshire Hathaway, Microsoft, and Tesla. The estimated betas vary over time and across varies but are always positive for each stock.' width=2100}\n:::\n:::\n\n\n## Parallelized Rolling-Window Estimation\n\nEven though we could now just apply the function using `group_by()` on the whole CRSP sample, we advise against doing it as it is computationally quite expensive. \nRemember that we have to perform rolling-window estimations across all stocks and time periods. \nHowever, this estimation problem is an ideal scenario to employ the power of parallelization. \nParallelization means that we split the tasks which perform rolling-window estimations across different workers (or cores on your local machine). \n\nFirst, we `nest()` the data by `permno`. Nested data means we now have a list of `permno` with corresponding time series data and an `industry` label. We get one row of output for each unique combination of non-nested variables which are `permno` and `industry`.\\index{Data!Nested}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_monthly_nested <- crsp_monthly |>\n  nest(data = c(month, ret_excess, mkt_excess))\ncrsp_monthly_nested\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30,384 × 3\n  permno industry      data              \n   <dbl> <chr>         <list>            \n1  10042 Mining        <tibble [264 × 3]>\n2  10043 Services      <tibble [159 × 3]>\n3  10057 Manufacturing <tibble [437 × 3]>\n4  10066 Services      <tibble [35 × 3]> \n5  10067 Manufacturing <tibble [12 × 3]> \n# ℹ 30,379 more rows\n```\n:::\n:::\n\n\nAlternatively, we could have created the same nested data by *excluding* the variables that we *do not* want to nest, as in the following code chunk. However, for many applications it is desirable to explicitly state the variables that are nested into the `data` list-column, so that the reader can track what ends up in there.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_monthly_nested <- crsp_monthly |>\n  nest(data = -c(permno, industry))\n```\n:::\n\n\nNext, we want to apply the `roll_capm_estimation()` function to each stock. This situation is an ideal use case for `map()`, which takes a list or vector as input and returns an object of the same length as the input. In our case, `map()` returns a single data frame with a time series of beta estimates for each stock. Therefore, we use `unnest()` to transform the list of outputs to a tidy data frame. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_monthly_nested |>\n  inner_join(examples, by = \"permno\") |>\n  mutate(beta = map(\n    data,\n    ~ roll_capm_estimation(., months = 60, min_obs = 48)\n  )) |>\n  unnest(beta) |>\n  select(permno, month, beta_monthly = beta) |>\n  drop_na()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,458 × 3\n  permno month      beta_monthly\n   <dbl> <date>            <dbl>\n1  10107 1990-03-01         1.39\n2  10107 1990-04-01         1.38\n3  10107 1990-05-01         1.43\n4  10107 1990-06-01         1.43\n5  10107 1990-07-01         1.45\n# ℹ 1,453 more rows\n```\n:::\n:::\n\n\nHowever, instead, we want to perform the estimations of rolling betas for different stocks in parallel. If you have a Windows machine, it makes most sense to define `multisession`, which means that separate R processes are running in the background on the same machine to perform the individual jobs. If you check out the documentation of `plan()`, you can also see other ways to resolve the parallelization in different environments.\\index{Parallelization}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = availableCores())\n```\n:::\n\n\nUsing eight cores, the estimation for our sample of around 25k stocks takes around 20 minutes. Of course, you can speed up things considerably by having more cores available to share the workload or by having more powerful cores. Notice the difference in the code below? All you need to do is to replace `map()` with `future_map()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_monthly <- crsp_monthly_nested |>\n  mutate(beta = future_map(\n    data, ~ roll_capm_estimation(., months = 60, min_obs = 48)\n  )) |>\n  unnest(c(beta)) |>\n  select(permno, month, beta_monthly = beta) |>\n  drop_na()\n```\n:::\n\n\n## Estimating Beta using Daily Returns\n\nBefore we provide some descriptive statistics of our beta estimates, we implement the estimation for the daily CRSP sample as well. \nDepending on the application, you might either use longer horizon beta estimates based on monthly data or shorter horizon estimates based on daily returns. \n\nFirst, we load daily CRSP data. \nNote that the sample is large compared to the monthly data, so make sure to have enough memory available.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_daily <- tbl(tidy_finance, \"crsp_daily\") |>\n  select(permno, month, date, ret_excess) |>\n  collect()\n```\n:::\n\n\nWe also need the daily Fama-French market excess returns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactors_ff3_daily <- tbl(tidy_finance, \"factors_ff3_daily\") |>\n  select(date, mkt_excess) |>\n  collect()\n```\n:::\n\n\nWe make sure to keep only relevant data to save memory space. \nHowever, note that your machine might not have enough memory to read the whole daily CRSP sample. In this case, we refer you to the exercises and try working with loops as in Chapter 3. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_daily <- crsp_daily |>\n  inner_join(factors_ff3_daily, by = \"date\") |>\n  select(permno, month, ret_excess, mkt_excess)\n```\n:::\n\n\nJust like above, we nest the data by `permno` for parallelization.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_daily_nested <- crsp_daily |>\n  nest(data = c(month, ret_excess, mkt_excess))\n```\n:::\n\n\nThis is what the estimation looks like for a couple of examples using `map()`. \nFor the daily data, we use the same function as above but only take 3 months of data and require at least 50 daily return observations in these months. \nThese restrictions help us to retrieve somewhat smooth coefficient estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_daily_nested |>\n  inner_join(examples, by = \"permno\") |>\n  mutate(beta_daily = map(\n    data,\n    ~ roll_capm_estimation(., months = 3, min_obs = 50)\n  )) |>\n  unnest(c(beta_daily)) |>\n  select(permno, month, beta_daily = beta) |>\n  drop_na()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,639 × 3\n  permno month      beta_daily\n   <dbl> <date>          <dbl>\n1  10107 1986-05-01      0.898\n2  10107 1986-06-01      0.906\n3  10107 1986-07-01      0.822\n4  10107 1986-08-01      0.900\n5  10107 1986-09-01      1.01 \n# ℹ 1,634 more rows\n```\n:::\n:::\n\n\nFor the sake of completeness, we tell our session again to use multiple workers for parallelization.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = availableCores())\n```\n:::\n\n\nThe code chunk for beta estimation using daily returns now looks very similar to the one for monthly data. The whole estimation takes around 30 minutes using eight cores and 16gb memory. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_daily <- crsp_daily_nested |>\n  mutate(beta_daily = future_map(\n    data, ~ roll_capm_estimation(., months = 3, min_obs = 50)\n  )) |>\n  unnest(c(beta_daily)) |>\n  select(permno, month, beta_daily = beta) |>\n  drop_na()\n```\n:::\n\n\n## Comparing Beta Estimates\n\nWhat is a typical value for stock betas? To get some feeling, we illustrate the dispersion of the estimated $\\hat\\beta_i$ across different industries and across time below. @fig-602 shows that typical business models across industries imply different exposure to the general market economy. However, there are barely any firms that exhibit a negative exposure to the market factor.\\index{Graph!Box plot}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrsp_monthly |>\n  left_join(beta_monthly, by = c(\"permno\", \"month\")) |>\n  drop_na(beta_monthly) |>\n  group_by(industry, permno) |>\n  summarize(beta = mean(beta_monthly), \n            .groups = \"drop\") |>\n  ggplot(aes(x = reorder(industry, beta, FUN = median), y = beta)) +\n  geom_boxplot() +\n  coord_flip() +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Firm-specific beta distributions by industry\"\n  )\n```\n\n::: {.cell-output-display}\n![The box plots show the average firm-specific beta estimates by industry.](beta-estimation_files/figure-html/fig-602-1.png){#fig-602 fig-alt='Title: Firm-specific beta distributions by industry. The figure shows box plots for each industry. Firms with the highest average CAPM beta belong to the public administration industry. Firms from the utility sector have the lowest average CAPM beta. The figure indicates very few outliers with negative CAPM betas. The large majority of all stocks has CAPM betas between 0.5 and 1.5.' width=2100}\n:::\n:::\n\n\nNext, we illustrate the time-variation in the cross-section of estimated betas. @fig-603 shows the monthly deciles of estimated betas (based on monthly data) and indicates an interesting pattern: First, betas seem to vary over time in the sense that during some periods, there is a clear trend across all deciles. Second, the sample exhibits periods where the dispersion across stocks increases in the sense that the lower decile decreases and the upper decile increases, which indicates that for some stocks the correlation with the market increases while for others it decreases. Note also here: stocks with negative betas are a rare exception.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_monthly |>\n  drop_na(beta_monthly) |>\n  group_by(month) |>\n  reframe(\n    x = quantile(beta_monthly, seq(0.1, 0.9, 0.1)),\n    quantile = 100 * seq(0.1, 0.9, 0.1)\n  ) |>\n  ggplot(aes(\n    x = month, \n    y = x, \n    color = as_factor(quantile),\n    linetype = as_factor(quantile)\n    )) +\n  geom_line() +\n  labs(\n    x = NULL, y = NULL, color = NULL, linetype = NULL,\n    title = \"Monthly deciles of estimated betas\",\n  )\n```\n\n::: {.cell-output-display}\n![Each line corresponds to the monthly cross-sectional quantile of the estimated CAPM beta.](beta-estimation_files/figure-html/fig-603-1.png){#fig-603 fig-alt='Title: Monthly deciles of estimated betas. The figure shows time series of deciles of estimated betas to illustrate the distribution of betas over time. The top 10 percent quantile on average is around 2 but varies substantially over time. The lowest 10 percent quantile is around 0.4 on average but is highly correlated with the top quantile such that in general CAPM market betas seem to go up and down jointly.' width=2100}\n:::\n:::\n\n\nTo compare the difference between daily and monthly data, we combine beta estimates to a single table. Then, we use the table to plot a comparison of beta estimates for our example stocks in @fig-604. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta <- beta_monthly |>\n  full_join(beta_daily, by = c(\"permno\", \"month\")) |>\n  arrange(permno, month)\n\nbeta |>\n  inner_join(examples, by = \"permno\") |>\n  pivot_longer(cols = c(beta_monthly, beta_daily)) |>\n  drop_na() |>\n  ggplot(aes(\n    x = month, \n    y = value, \n    color = name, \n    linetype = name\n    )) +\n  geom_line() +\n  facet_wrap(~company, ncol = 1) +\n  labs(\n    x = NULL, y = NULL, color = NULL, linetype = NULL, \n    title = \"Comparison of beta estimates using monthly and daily data\"\n  )\n```\n\n::: {.cell-output-display}\n![CAPM betas are computed using 5 years of monthly or 3 months of daily data. The two lines show the monthly estimates based on a rolling window for few exemplary stocks.](beta-estimation_files/figure-html/fig-604-1.png){#fig-604 fig-alt='Title: Comparison of beta estimates using monthly and daily data. The figure shows a time series of beta estimates using 5 years of monthly versus 3 years of daily data for Apple, Berkshire Hathaway, Microsoft, and Tesla. The estimates based on longer periods of monthly data are smooth relative to the estimates based on daily data. However, the general trend and level is similar, irrespective of the choice of frequency.' width=2100}\n:::\n:::\n\n\nThe estimates in @fig-604 look as expected. As you can see, it really depends on the estimation window and data frequency how your beta estimates turn out. \n\nFinally, we write the estimates to our database such that we can use them in later chapters. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n  dbWriteTable(tidy_finance,\n    \"beta\",\n    value = beta,\n    overwrite = TRUE\n  )\n```\n:::\n\n\nWhenever you perform some kind of estimation, it also makes sense to do rough plausibility tests. A possible check is to plot the share of stocks with beta estimates over time. \nThis descriptive helps us discover potential errors in our data preparation or estimation procedure. \nFor instance, suppose there was a gap in our output where we do not have any betas. \nIn this case, we would have to go back and check all previous steps to find out what went wrong. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_long <- crsp_monthly |>\n  left_join(beta, by = c(\"permno\", \"month\")) |>\n  pivot_longer(cols = c(beta_monthly, beta_daily))\n\nbeta_long |>\n  group_by(month, name) |>\n  summarize(share = sum(!is.na(value)) / n()) |>\n  ggplot(aes(\n    x = month, \n    y = share, \n    color = name,\n    linetype = name\n    )) +\n  geom_line() +\n  scale_y_continuous(labels = percent) +\n  labs(\n    x = NULL, y = NULL, color = NULL, linetype = NULL,\n    title = \"End-of-month share of securities with beta estimates\"\n  ) +\n  coord_cartesian(ylim = c(0, 1))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'month'. You can override using\nthe `.groups` argument.\n```\n:::\n\n::: {.cell-output-display}\n![The two lines show the share of securities with beta estimates using 5 years of monthly or 3 months of daily data.](beta-estimation_files/figure-html/fig-605-1.png){#fig-605 fig-alt='Title: End-of-month share of securities with beta estimates. The figure shows two time series with end-of-year shares of securities with beta estimates using 5 years of monthly or 3 months of daily data. There is almost no missing data for the estimates based on daily data. For the beta estimates based on monthly data, around 75 percent of all stock-month combinations provide sufficient long historical periods to estimate the  beta.' width=2100}\n:::\n:::\n\n\n@fig-605 does not indicate any troubles, so let us move on to the next check. \n\nWe also encourage everyone to always look at the distributional summary statistics of variables. You can easily spot outliers or weird distributions when looking at such tables.\\index{Summary statistics}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_long |>\n  select(name, value) |>\n  drop_na() |>\n  group_by(name) |>\n  summarize(\n    mean = mean(value),\n    sd = sd(value),\n    min = min(value),\n    q05 = quantile(value, 0.05),\n    q50 = quantile(value, 0.50),\n    q95 = quantile(value, 0.95),\n    max = max(value),\n    n = n()\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 9\n  name          mean    sd   min    q05   q50   q95   max       n\n  <chr>        <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>   <int>\n1 beta_daily   0.752 0.924 -43.7 -0.440 0.690  2.23  56.6 3286117\n2 beta_monthly 1.10  0.721 -13.0  0.120 1.04   2.34  11.8 2135342\n```\n:::\n:::\n\n\nThe summary statistics also look plausible for the two estimation procedures. \n\nFinally, since we have two different estimators for the same theoretical object, we expect the estimators should be at least positively correlated (although not perfectly as the estimators are based on different sample periods and frequencies).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta |>\n  select(beta_daily, beta_monthly) |>\n  cor(use = \"complete.obs\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             beta_daily beta_monthly\nbeta_daily        1.000        0.325\nbeta_monthly      0.325        1.000\n```\n:::\n:::\n\n\nIndeed, we find a positive correlation between our beta estimates. In the subsequent chapters, we mainly use the estimates based on monthly data as most readers should be able to replicate them due to potential memory limitations that might arise with the daily data. \n\n## Exercises\n\n1. Compute beta estimates based on monthly data using 1, 3, and 5 years of data and impose a minimum number of observations of 10, 28, and 48 months with return data, respectively. How strongly correlated are the estimated betas?\n1. Compute beta estimates based on monthly data using 5 years of data and impose different numbers of minimum observations. How does the share of permno-month observations with successful beta estimates vary across the different requirements? Do you find a high correlation across the estimated betas? \n1. Instead of using `future_map()`, perform the beta estimation in a loop (using either monthly or daily data) for a subset of 100 permnos of your choice. Verify that you get the same results as with the parallelized code from above.\n1. Filter out the stocks with negative betas. Do these stocks frequently exhibit negative betas, or do they resemble estimation errors? \n1. Compute beta estimates for multi-factor models such as the Fama-French 3 factor model. For that purpose, you extend your regression to \n$$\nr_{i, t} - r_{f, t} = \\alpha_i + \\sum\\limits_{j=1}^k\\beta_{i,k}(r_{j, t}-r_{f,t})+\\varepsilon_{i, t}\n$$\nwhere $r_{j, t}$ are the $k$ factor returns. Thus, you estimate 4 parameters ($\\alpha_i$ and the slope coefficients). Provide some summary statistics of the cross-section of firms and their exposure to the different factors. ",
    "supporting": [
      "beta-estimation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}