[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"\nwebsite online version Tidy Finance R, book currently development intended eventual print release. grateful kind feedback every aspect book. please get touch us via contact@tidy-finance.org spot typos, discover issues deserve attention, suggestions additional chapters sections.","code":""},{"path":"index.html","id":"authors","chapter":"Welcome","heading":"Authors","text":"book result joint effort three people (alphabetical order last names):Christoph Scheuch Director Product social trading platform wikifolio.com responsible product planning, execution monitoring also manages team data scientists analyze user behavior develop new products.Stefan Voigt Assistant Professor Finance Department Economics University Copenhagen research fellow Danish Finance Institute. research focuses blockchain technology, high-frequency trading financial econometrics. Stefan teaches parts book courses empirical finance.Patrick Weiss Post-Doc Vienna University Economics Business. research centers around intersection asset pricing corporate finance.met Vienna Graduate School Finance us graduated different focus, shared passion: coding R. years painful trial error, decided share learnings public form book.","code":""},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"book licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International CC -NC-SA 4.0.code samples book licensed Creative Commons CC0 1.0 Universal (CC0 1.0), .e. public domain.","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"why-does-this-book-exist","chapter":"Preface","heading":"Why does this book exist?","text":"Finance exciting area economic research broad range academic real-world empirical applications. student, researcher data analyst, typically exposed different types financial data, including asset prices, accounting data transaction histories, just name examples.\nDespite vast number empirical studies financial phenomenons, one quickly learns actual implementation typically rather opaque.\ngraduate students, particularly surprised lack public code seminal papers even textbooks key concepts financial economics. lack transparent codes leads numerous replication efforts (failures), also waste resources problems already solved countless others secrecy.book aims lift curtain reproducible finance providing fully transparent code base many common financial applications. hope inspire others sharing code publicly taking part journey towards reproducible research future.","code":""},{"path":"preface.html","id":"who-should-read-this-book","chapter":"Preface","heading":"Who should read this book?","text":"write book three audiences:Students want acquire basic tools required conduct financial research ranging undergrad graduate level. structure book kept simple enough material sufficient self-study purposes.Instructors look materials teach empirical finance courses. provide plenty examples (hopefully) intuitive explanations can easily adjusted expanded.Data analysts statisticians work issues pertaining financial data need practical tools .","code":""},{"path":"preface.html","id":"what-will-you-learn","chapter":"Preface","heading":"What will you learn?","text":"book divided 5 main parts:Chapter 1 introduces important concepts around approach Tidy Finance revolves.Chapter 2 provides tools organize data prepare common data sets used financial research: CRSP Compustat.Chapters 3-7 deal key concepts empirical asset pricing beta estimation, portfolio sorts performance analysis.Chapters 8-9 apply machine learning methods problems factor selection option pricing.Chapters 10-11 provide approaches parametric constrained portfolio optimization backtesting procedures.","code":""},{"path":"preface.html","id":"what-wont-you-learn","chapter":"Preface","heading":"What won’t you learn?","text":"book empirical work. assume basic knowledge statistics econometrics, provide detailed treatments methods applied book. Instead, find references seminal academic work journal articles detailed treatments.\nbelieve comparative advantage provide thorough implementation portfolio sorts, backtesting procedures, machine learning methods related topics empirical finance together discussions needy-greedy choices face conducting empirical analysis.\nInstead discussing, instance, statistical properties well-established tools use book, hence confidently stand shoulders giants.","code":""},{"path":"preface.html","id":"why-r","chapter":"Preface","heading":"Why R?","text":"believe R among best choices programming language area finance. favorite features include:R free open source, can use academic professional contextsA diverse active online community working broad range toolsA massive set actively maintained packages kinds applications, e.g. data manipulation, visualization, machine learning, etc.Powerful tools communication, e.g. Rmarkdown shinyRStudio one best development environments interactive data analysisStrong foundation functional programmingSmooth integration programming languages, e.g., SQL, Python, C, C++, Fortran, etc.information, refer Wickham et al. (2019).","code":""},{"path":"preface.html","id":"why-tidy","chapter":"Preface","heading":"Why tidy?","text":"start working data, quickly realize spend lot time reading, cleaning transforming data. fact, often said 80% data analysis spent preparing data. tidying data, want structure data sets facilitate analyses. Wickham (2014) puts :[T]idy datasets alike every messy dataset messy way. Tidy datasets provide standardized way link structure dataset (physical layout) semantics (meaning).essence, tidy data follows three principles:Every column variable.Every row observation.Every cell single value.Throughout book, try follow principles best can. want learn tidy data principles informal manner, refer vignette.addition data layer, also tidy coding principles outlined tidy tools manifesto try follow:Reuse existing data structures.Compose simple functions pipe.Embrace functional programming.Design humans.particular, heavily draw set packages called tidyverse (Wickham et al. 2019). tidyverse consistent set packages data analysis tasks, ranging importing, wrangling visualizing modeling data grammar. addition explicit tidy principles, tidyverse benefits: () master one package, easier master others (ii) core packages developed maintained Public Benefit Company RStudio, Inc. ","code":""},{"path":"preface.html","id":"prerequisites","chapter":"Preface","heading":"Prerequisites","text":"continue, make sure software need book:Install R RStudio. get walk-installation every major operating system, follow steps outlined summary. whole process done clicks. wonder difference: R open-source language environment statistical computing graphics, free download use. R runs computations, RStudio integrated development environment provides interface adding many convenient features tools. suggest coding RStudio.Open RStudio install tidyverse. sure works? find helpful information install packages brief summary.new R, recommend start following sources:gentle good introduction workings R can found . done setting R machine, try follow “weighted dice project.”main book tidyverse available online free: R Data Science Hadley Wickham Garrett Grolemund explains majority tools use book.","code":""},{"path":"preface.html","id":"colophon","chapter":"Preface","heading":"Colophon","text":"book written RStudio using bookdown. website hosted github pages, automatically updated every commit. complete source available GitHub. generated plots book using ggplot2 classic dark--light theme (theme_bw()).version book built R version 4.1.2 (2021-11-01) following packages:","code":""},{"path":"introduction-to-tidy-finance.html","id":"introduction-to-tidy-finance","chapter":"1 Introduction to Tidy Finance","heading":"1 Introduction to Tidy Finance","text":"main aim chapter familiarize tidyverse. start downloading visualizing stock data move simple portfolio choice problem. examples introduce approach Tidy Finance.","code":""},{"path":"introduction-to-tidy-finance.html","id":"working-with-stock-market-data","chapter":"1 Introduction to Tidy Finance","heading":"1.1 Working with stock market data","text":"start session, load required packages.\nThroughout entire book always use package tidyverse.\nchapter load convenient tidyquant package download price data.\ntypically install package can load . case done yet, call install.packages(\"tidyquant\").\ntrouble using tidyquant, check documentation.first download daily prices one stock market ticker, e.g., AAPL, directly data provider Yahoo!Finance.\ndownload data, can use command tq_get. know use , make sure read help file calling ?tq_get.\nespecially recommend taking look documentation’s examples section.tq_get downloads stock market data Yahoo!Finance specify another data source. function returns tibble eight quite self-explanatory columns: symbol, date, market prices open, high, low close, daily volume (number traded shares), adjusted price USD. adjusted prices corrected anything might affect stock price market closes, e.g., stock splits dividends. actions affect quoted prices, direct impact investors hold stock.Next, use ggplot2 visualize time series adjusted prices.Instead analyzing prices, compute daily returns defined \\((p_t - p_{t-1}) / p_{t-1}\\) \\(p_t\\) adjusted day \\(t\\) price. function lag computes previous value vector.resulting tibble contains three columns last contains daily returns. Note first entry naturally contains NA previous price. Additionally, computations require time series ordered date.\nOtherwise, lag meaningless.upcoming examples, remove missing values require separate treatment computing, e.g., sample averages. general, however, make sure understand NA values occur carefully examine can simply get rid observations.Next, visualize distribution daily returns histogram. convenience, multiply returns 100 get returns percent visualizations. Additionally, also add dashed red line indicates 5% quantile daily returns histogram, (crude) proxy worst return stock probability least 5%., bins = 100 determines number bins hence implicitly width bins.\nproceeding, make sure understand use geom geom_vline() add dotted red line indicates 5% quantile daily returns.\ntypical task proceeding data compute summary statistics main variables interest.see maximum daily return around 11.981 percent.\ncan also compute summary statistics year imposing group_by(year = year(date)), call year(date) computes year.case wonder: additional argument .names = \"{.fn}\" across() determines name output columns. specification rather flexible allows almost arbitrary column names can useful reporting.","code":"\nlibrary(tidyverse)\nlibrary(tidyquant)\nprices <- tq_get(\"AAPL\", get = \"stock.prices\")\nprices## # A tibble: 2,551 x 8\n##   symbol date        open  high   low close    volume adjusted\n##   <chr>  <date>     <dbl> <dbl> <dbl> <dbl>     <dbl>    <dbl>\n## 1 AAPL   2012-01-03  14.6  14.7  14.6  14.7 302220800     12.6\n## 2 AAPL   2012-01-04  14.6  14.8  14.6  14.8 260022000     12.6\n## 3 AAPL   2012-01-05  14.8  14.9  14.7  14.9 271269600     12.8\n## 4 AAPL   2012-01-06  15.0  15.1  15.0  15.1 318292800     12.9\n## 5 AAPL   2012-01-09  15.2  15.3  15.0  15.1 394024400     12.9\n## # ... with 2,546 more rows\nprices %>%\n  ggplot(aes(x = date, y = adjusted)) +\n  geom_line() +\n  labs(\n    x = NULL, \n    y = NULL,\n    title = \"AAPL stock prices\",\n    subtitle = \"Prices in USD, adjusted for dividend payments and stock splits\"\n  )\nreturns <- prices %>%\n  arrange(date) %>%\n  mutate(ret = (adjusted - lag(adjusted)) / lag(adjusted)) %>%\n  select(symbol, date, ret)\nreturns## # A tibble: 2,551 x 3\n##   symbol date            ret\n##   <chr>  <date>        <dbl>\n## 1 AAPL   2012-01-03 NA      \n## 2 AAPL   2012-01-04  0.00537\n## 3 AAPL   2012-01-05  0.0111 \n## 4 AAPL   2012-01-06  0.0105 \n## 5 AAPL   2012-01-09 -0.00159\n## # ... with 2,546 more rows\nreturns <- returns %>%\n  drop_na(ret)\nquantile_05 <- quantile(returns %>% pull(ret) * 100, 0.05)\n\nreturns %>%\n  ggplot(aes(x = ret * 100)) +\n  geom_histogram(bins = 100) +\n  geom_vline(aes(xintercept = quantile_05),\n    color = \"red\",\n    linetype = \"dashed\"\n  ) +\n  labs(\n    x = NULL, \n    y = NULL,\n    title = \"Distribution of daily AAPL returns (in percent)\",\n    subtitle = \"The dotted vertical line indicates the historical 5% quantile\"\n  )\nreturns %>%\n  mutate(ret = ret * 100) %>%\n  summarise(across(\n    ret,\n    list(\n      daily_mean = mean,\n      daily_sd = sd,\n      daily_min = min,\n      daily_max = max\n    )\n  ))## # A tibble: 1 x 4\n##   ret_daily_mean ret_daily_sd ret_daily_min ret_daily_max\n##            <dbl>        <dbl>         <dbl>         <dbl>\n## 1          0.118         1.79         -12.9          12.0\nreturns %>%\n  mutate(ret = ret * 100) %>%\n  group_by(year = year(date)) %>%\n  summarise(across(\n    ret,\n    list(\n      daily_mean = mean,\n      daily_sd = sd,\n      daily_min = min,\n      daily_max = max\n    ),\n    .names = \"{.fn}\"\n  ))## # A tibble: 11 x 5\n##    year daily_mean daily_sd daily_min daily_max\n##   <dbl>      <dbl>    <dbl>     <dbl>     <dbl>\n## 1  2012    0.124       1.86     -6.44      8.87\n## 2  2013    0.0472      1.80    -12.4       5.14\n## 3  2014    0.145       1.36     -7.99      8.20\n## 4  2015    0.00199     1.68     -6.12      5.74\n## 5  2016    0.0575      1.47     -6.57      6.50\n## # ... with 6 more rows"},{"path":"introduction-to-tidy-finance.html","id":"scaling-up-the-analysis","chapter":"1 Introduction to Tidy Finance","heading":"1.2 Scaling up the analysis","text":"next step, generalize code computations can handle arbitrary vector tickers (e.g., constituents index). Following tidy principles, quite easy download data, plot price time series, tabulate summary statistics arbitrary number assets.tidyverse magic starts: tidy data makes extremely easy generalize computations many assets like. following code takes vector tickers, e.g., ticker <- c(\"AAPL\", \"MMM\", \"BA\"), automates download well plot price time series. end, create table summary statistics arbitrary number assets. perform analysis data current constituents Dow Jones Industrial Average index.resulting file contains 158345 daily observations total 29 different corporations. figure illustrates time series downloaded adjusted prices constituents Dow Jones index. Make sure understand every single line code! (arguments aes()? alternative geoms use visualize time series? Hint: know answers try change code see difference intervention causes).notice small differences relative code used ? tq_get(ticker) returns tibble several symbols well. need illustrate tickers simultaneously include color = symbol ggplot2 aesthetics. way, generate separate line ticker. course, simply many lines graph properly identify individual stocks, illustrates point well.holds stock returns. computing returns, use group_by(symbol) mutate command performed symbol individually. logic applies computation summary statistics: group_by(symbol) key aggregating time series ticker-specific variables interest.Note now also equipped tools download price data ticker listed S&P 500 index number lines code. Just use ticker <- tq_index(\"SP500\"), provides tibble contains symbol (currently) part S&P 500. However, don’t try prepared wait couple minutes quite data download!","code":"\nticker <- tq_index(\"DOW\") \nindex_prices <- tq_get(ticker,\n  get = \"stock.prices\",\n  from = \"2000-01-01\"\n) %>%\n  filter(symbol != \"DOW\") # Exclude the index itself\nindex_prices %>%\n  ggplot(aes(\n    x = date,\n    y = adjusted,\n    color = symbol\n  )) +\n  geom_line() +\n  labs(\n    x = NULL,\n    y = NULL,\n    color = NULL,\n    title = \"DOW index stock prices\",\n    subtitle = \"Prices in USD, adjusted for dividend payments and stock splits\"\n  ) +\n  theme(legend.position = \"none\")\nall_returns <- index_prices %>%\n  group_by(symbol) %>%\n  mutate(ret = adjusted / lag(adjusted) - 1) %>%\n  select(symbol, date, ret) %>%\n  drop_na(ret)\n\nall_returns %>%\n  mutate(ret = ret * 100) %>%\n  group_by(symbol) %>%\n  summarise(across(\n    ret,\n    list(\n      daily_mean = mean,\n      daily_sd = sd,\n      daily_min = min,\n      daily_max = max\n    ),\n        .names = \"{.fn}\"\n  ))## # A tibble: 29 x 5\n##   symbol daily_mean daily_sd daily_min daily_max\n##   <chr>       <dbl>    <dbl>     <dbl>     <dbl>\n## 1 AMGN       0.0469     1.99     -13.4      15.1\n## 2 AXP        0.0576     2.30     -17.6      21.9\n## 3 BA         0.0617     2.20     -23.8      24.3\n## 4 CAT        0.0684     2.04     -14.5      14.7\n## 5 CRM        0.122      2.68     -27.1      26.0\n## # ... with 24 more rows"},{"path":"introduction-to-tidy-finance.html","id":"other-forms-of-data-aggregation","chapter":"1 Introduction to Tidy Finance","heading":"1.3 Other forms of data aggregation","text":"course, aggregation across variables symbol can make sense well. instance, suppose interested answering question: days high aggregate trading volume likely followed days high aggregate trading volume? provide initial analysis question, take downloaded prices compute aggregate daily trading volume Dow Jones constituents USD. Recall column volume denoted number traded shares. Thus, multiply trading volume daily closing price get proxy aggregate trading volume USD. Scaling 1e9 denotes daily trading volume billion USD.One way illustrate persistence trading volume plot volume day \\(t\\) volume day \\(t-1\\) example . add 45°-line indicate hypothetical one--one relation geom_abline, addressing potential differences axes’ scales.understand warning ## Warning: Removed 1 rows containing missing values (geom_point). comes means? Purely eye-balling reveals days high trading volume often followed similarly high trading volume days.","code":"\nvolume <- index_prices %>%\n  mutate(volume_usd = volume * close / 1e9) %>%\n  group_by(date) %>%\n  summarise(volume = sum(volume_usd))\n\nvolume %>%\n  ggplot(aes(x = date, y = volume)) +\n  geom_line() +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Aggregate daily trading volume (billion USD)\"\n  ) \nvolume %>%\n  ggplot(aes(x = lag(volume), y = volume)) +\n  geom_point() +\n  geom_abline(aes(intercept = 0, slope = 1),\n    color = \"red\",\n    linetype = \"dotted\"\n  ) +\n  labs(\n    x = \"Previous day aggregate trading volume (billion USD)\",\n    y = \"Aggregate trading volume (billion USD)\",\n    title = \"Persistence of trading volume\"\n  )## Warning: Removed 1 rows containing missing values (geom_point)."},{"path":"introduction-to-tidy-finance.html","id":"portfolio-choice-problems","chapter":"1 Introduction to Tidy Finance","heading":"1.4 Portfolio choice problems","text":"previous part, show download stock market data inspect graphs summary statistics. Now, move typical question Finance, namely, optimally allocate wealth across different assets. standard framework optimal portfolio selection considers investors prefer higher future returns dislike future return volatility (defined square root return variance): mean-variance investor.essential tool evaluate portfolios mean-variance context efficient frontier, set portfolios satisfy condition portfolio exists higher expected return volatility (.e., risk). compute visualize efficient frontier several stocks.\nFirst, extract asset’s monthly returns. order keep things simple work balanced panel exclude tickers observe price every single trading day since 2000.Next, transform returns tidy tibble \\((T \\times N)\\) matrix one column \\(N\\) tickers compute covariance matrix \\(\\Sigma\\) also expected return vector \\(\\mu\\). achieve using pivot_wider() new column names column symbol set values ret.\ncompute vector sample average returns sample variance-covariance matrix, consider proxies parameters future returns., compute minimum variance portfolio weights \\(\\omega_\\text{mvp}\\) well expected return \\(\\omega_\\text{mvp}'\\mu\\) volatility \\(\\sqrt{\\omega_\\text{mvp}'\\Sigma\\omega_\\text{mvp}}\\) portfolio. Recall minimum variance portfolio vector portfolio weights solution \n\\[\\omega_\\text{mvp} = \\arg\\min w'\\Sigma w \\text{ s.t. } \\sum\\limits_{=1}^Nw_i = 1.\\]\neasy show analytically, \\(\\omega_\\text{mvp} = \\frac{\\Sigma^{-1}\\iota}{\\iota'\\Sigma^{-1}\\iota}\\) \\(\\iota\\) vector ones.Note monthly volatility minimum variance portfolio order magnitude daily standard deviation individual components. Thus, diversification benefits terms risk reduction tremendous!Next, set find weights portfolio achieves three times expected return minimum variance portfolio. However, mean-variance investors interested portfolio achieves required return, rather efficient portfolio, .e., portfolio lowest standard deviation.\nwonder solution \\(\\omega_\\text{eff}\\) comes : efficient portfolio chosen investor aims achieve minimum variance given minimum acceptable expected return \\(\\bar{\\mu}\\). Hence, objective function choose \\(\\omega_\\text{eff}\\) solution \n\\[\\omega_\\text{eff}(\\bar{\\mu}) = \\arg\\min w'\\Sigma w \\text{ s.t. } w'\\iota = 1 \\text{ } \\omega'\\mu \\geq \\bar{\\mu}.\\]\ncode implements analytic solution optimization problem benchmark return \\(\\bar\\mu\\) set 3 times expected return minimum variance portfolio. encourage verify correct.","code":"\nindex_prices <- index_prices %>%\n  group_by(symbol) %>%\n  mutate(n = n()) %>%\n  ungroup() %>%\n  filter(n == max(n)) %>%\n  select(-n)\n\nreturns <- index_prices %>%\n  mutate(month = floor_date(date, \"month\")) %>%\n  group_by(symbol, month) %>%\n  summarise(price = last(adjusted), .groups = \"drop_last\") %>%\n  mutate(ret = price / lag(price) - 1) %>%\n  drop_na(ret) %>%\n  select(-price)\nreturns_matrix <- returns %>%\n  pivot_wider(\n    names_from = symbol,\n    values_from = ret\n  ) %>%\n  select(-month)\n\nsigma <- cov(returns_matrix)\nmu <- colMeans(returns_matrix)\nN <- ncol(returns_matrix)\niota <- rep(1, N)\nmvp_weights <- solve(sigma) %*% iota\nmvp_weights <- mvp_weights / sum(mvp_weights)\n\ntibble(expected_ret = t(mvp_weights) %*% mu, volatility = sqrt(t(mvp_weights) %*% sigma %*% mvp_weights))## # A tibble: 1 x 2\n##   expected_ret[,1] volatility[,1]\n##              <dbl>          <dbl>\n## 1          0.00831         0.0314\nmu_bar <- 3 * t(mvp_weights) %*% mu\n\nC <- as.numeric(t(iota) %*% solve(sigma) %*% iota)\nD <- as.numeric(t(iota) %*% solve(sigma) %*% mu)\nE <- as.numeric(t(mu) %*% solve(sigma) %*% mu)\n\nlambda_tilde <- as.numeric(2 * (mu_bar - D / C) / (E - D^2 / C))\nefp_weights <- mvp_weights + lambda_tilde / 2 * (solve(sigma) %*% mu - D / C * solve(sigma) %*% iota)"},{"path":"introduction-to-tidy-finance.html","id":"the-efficient-frontier","chapter":"1 Introduction to Tidy Finance","heading":"1.5 The efficient frontier","text":"two mutual fund separation theorem states soon two efficient portfolios (minimum variance portfolio efficient portfolio another required level expected returns like ), can characterize entire efficient frontier combining two portfolios. code implements construction efficient frontier, characterizes highest expected return achievable level risk. understand code better, make sure familiarize inner workings loop.Finally, simple visualize efficient frontier alongside two efficient portfolios within one, powerful figure using ggplot2. also add individual stocks call.\nblack line indicates efficient frontier: set portfolios mean-variance efficient investor choose . Compare performance relative individual assets (blue dots) - become clear diversifying yields massive performance gains (least long take parameters \\(\\Sigma\\) \\(\\mu\\) given).","code":"\nc <- seq(from = -0.4, to = 1.9, by = 0.01)\nres <- tibble(\n  c = c,\n  mu = NA,\n  sd = NA\n)\n\nfor (i in seq_along(c)) {\n  w <- (1 - c[i]) * mvp_weights + (c[i]) * efp_weights\n  res$mu[i] <- 12 * 100 * t(w) %*% mu\n  res$sd[i] <- 12 * sqrt(100) * sqrt(t(w) %*% sigma %*% w)\n}\nres %>%\n  ggplot(aes(x = sd, y = mu)) +\n  geom_point() +\n  geom_point( # locate the minimum variance and efficient portfolio\n    data = res %>% filter(c %in% c(0, 1)),\n    color = \"red\",\n    size = 4\n  ) +\n  geom_point( # locate the individual assets\n    data = tibble(mu = 12 * 100 * mu, sd = 12 * 10 * sqrt(diag(sigma))),\n    aes(y = mu, x = sd), color = \"blue\", size = 1\n  ) +\n  labs(\n    x = \"Annualized standard deviation (in percent)\",\n    y = \"Annualized expected return (in percent)\",\n    title = \"Dow Jones asset returns and efficient frontier\",\n    subtitle = \"Red dots indicate the location of the minimum variance and efficient tangency portfolio\"\n  )"},{"path":"introduction-to-tidy-finance.html","id":"exercises","chapter":"1 Introduction to Tidy Finance","heading":"1.6 Exercises","text":"Download daily prices another stock market ticker choice Yahoo!Finance tq_get tidyquant package. Plot two time series ticker’s un-adjusted adjusted closing prices. Explain differences.Compute daily net returns asset visualize distribution daily returns histogram. Also, use geom_vline() add dashed red line indicates 5% quantile daily returns within histogram. Compute summary statistics (mean, standard deviation, minimum maximum) daily returnsTake code generalize can perform computations arbitrary vector tickers (e.g., ticker <- c(\"AAPL\", \"MMM\", \"BA\")). Automate download, plot price time series, create table return summary statistics arbitrary number assets.Consider research question: days high aggregate trading volume often also days large absolute price changes? Find appropriate visualization analyze question.Compute monthly returns downloaded stock market prices. Compute vector historical average returns sample variance-covariance matrix. compute minimum variance portfolio weights portfolio volatility average returns, visualize mean-variance efficient frontier. Choose one assets identify portfolio yields historical volatility achieves highest possible average return.portfolio choice analysis restricted sample assets trading every single day since 2000. decision problem want infer future expected portfolio performance results?efficient frontier characterizes portfolios highest expected return different levels risk, .e., standard deviation. Identify portfolio highest expected return per standard deviation. Hint: ratio expected return standard deviation important concept Finance.","code":""}]
