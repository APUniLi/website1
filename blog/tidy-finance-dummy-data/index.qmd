---
title: "Dummy Data for Tidy Finance Readers without Access to WRDS"
author:
  - name: Christoph Scheuch
    url: https://christophscheuch.github.io/
    affiliations:
      - name: wikifolio Financial Technologies AG
date: "2023-09-11"
description: R code to generate dummy data that can be used to run the examples in Tidy Finance with R or Python
image: thumbnail.png
image-alt: An image of a stylized company building on a screen in the middle of a room. The room has a futuristic setting, with a backdrop of a digital, grid-like landscape symbolizing the internet. The color palette should be a combination of cool blues and warm yellow. Created with DALL-E 2.
categories: 
  - Data
---

Since we published our book [Tidy Finance with R](../../r/index.qmd), we have received emails from readers who don't have access to WRDS and hence cannot run the code we provide. To alleviate their constraints, we decided to create a dummy database that contains all tables and corresponding columns such that all code chunks in our book can be executed with this dummy database. We deliberately use the *dummy* label because the data is not meaningful in the sense that it allows readers to replicate the results of the book. For legal reasons, the data is also *not* a sample of the original data.

In this blog post, we use the following packages:

```{r}
library(tidyverse)
library(RSQLite)
```


```{r}
tidy_finance <- dbConnect(
  SQLite(),
  "../../data/tidy_finance.sqlite",
  extended_types = TRUE
)

tidy_finance_dummy <- dbConnect(
  SQLite(),
  "../../data/tidy_finance_dummy.sqlite",
  extended_types = TRUE
)
```

Since we draw
```{r}
set.seed(1234)

start_date <- as.Date("2000-01-01")
end_date <- as.Date("2023-08-01")

time_series_years <- seq(year(start_date), year(end_date), 1)
time_series_months <- seq(start_date, end_date, "1 month")
time_series_days <- seq(start_date, end_date, "1 day")
```


## Create macro dummy data

The code aims to create dummy data for the macroeconomic tables. It does this by replacing the original data with random numbers while preserving the time structure (either daily or monthly) and column names. We iterate over each table name in the macro_tables vector. For each table, the data is fetched from the database and stored in the `data_original` table. The code checks the column names of the `data_original` to determine if the data is structured by months or by days. Depending on the structure, it sets the appropriate time series and date column name. For each relevant column (i.e., not a date column), the code generates a command to replace its values with random numbers drawn from a uniform distribution between 0 and 1. Finally, the table with the dummy data is written to the nwe database with dummy data.

We do not put any meaningful structure on the macro tables because they can be freely downloaded from the original sources - check out [Accessing and Managing Financial Data](../../r/accessing-and-managing-financial-data.qmd).

```{r}
macro_tables <- c(
  "cpi_monthly", "factors_ff3_daily", 
  "factors_ff3_monthly",
  "factors_ff5_monthly", "factors_q_monthly",
  "industries_ff_monthly", "macro_predictors"
)

for (table_name in macro_tables) {
  data_original <- tbl(tidy_finance, table_name) |>
    collect() |> 
    drop_na()
  
  if ("month" %in% names(data_original)) {
    time_series <- time_series_months
    date_column <- "month"
  } else if ("date" %in% names(data_original)) {
    time_series <- time_series_days
    date_column <- "date"
  }
  
  relevant_columns <- data_original |> 
    select(-contains(c("month", "date"))) |> 
    names()
  
  commands <- unlist(
    map(
      relevant_columns, 
      ~rlang::exprs(!!..1 := runif(n()))
    )
  )
  
  data_dummy <- tibble(
    !!sym(date_column) := time_series
    ) |> 
    mutate(
      !!!commands
    )
  
  dbWriteTable(tidy_finance_dummy, table_name, 
               data_dummy, overwrite = TRUE)
}
```

## Create stock dummy data

The next code generates a dataset of stock identifiers with unique `permno` and `gvkey` values, as well as associated `exchange`, `industry`, `exchcd`, and `siccd` values. The generated dataset is based on the characteristics of stocks in the `crsp_monthly` table of the `tidy_finance` database, ensuring that the generated stocks reflect the distribution of industries and exchanges in the original data.

```{r}
number_of_stocks <- 100

crsp_stocks <- tbl(tidy_finance, "crsp_monthly") |>
  group_by(permno) |> 
  filter(month == max(month, na.rm = TRUE)) |> 
  ungroup() |> 
  select(permno, gvkey, industry, exchange, exchcd, siccd) |> 
  collect()

industries <- crsp_stocks |> 
  filter(industry != "Missing") |> 
  count(industry) |> 
  mutate(prob = n / sum(n))

exchanges <- crsp_stocks |> 
  filter(exchange != "Other") |> 
  count(exchange) |> 
  mutate(prob = n / sum(n))

stock_identifiers <- 1:number_of_stocks |> 
  map_df(
    function(x) {
      tibble(
        permno = x,
        gvkey = as.character(x + 10000),
        exchange = sample(exchanges$exchange, 1, 
                          prob = exchanges$prob),
        industry = sample(industries$industry, 1, 
                          prob = industries$prob)
      ) |> 
        mutate(
          exchcd = case_when(
            exchange == "NYSE" ~ sample(c(1, 31), n()),
            exchange == "AMEX" ~ sample(c(2, 32), n()),
            exchange == "NASDAQ" ~ sample(c(3, 33), n())
          ),
          siccd = case_when(
            industry == "Agriculture" ~ sample(1:999, n()),
            industry == "Mining" ~ sample(1000:1499, n()),
            industry == "Construction" ~ sample(1500:1799, n()),
            industry == "Manufacturing" ~ sample(1800:3999, n()),
            industry == "Transportation" ~ sample(4000:4899, n()),
            industry == "Utilities" ~ sample(4900:4999, n()),
            industry == "Wholesale" ~ sample(5000:5199, n()),
            industry == "Retail" ~ sample(5200:5999, n()),
            industry == "Finance" ~ sample(6000:6799, n()),
            industry == "Services" ~ sample(7000:8999, n()),
            industry == "Public" ~ sample(9000:9999, n())
          )
        )
    }
  )
```

In this code chunk, we construct three panels of stock data with varying frequencies: yearly, monthly, and daily. We begin by creating the `stock_panel_yearly` panel. To achieve this, we combine the `stock_identifiers` dataset with a new dataset containing the variable `year` from `time_series_years`. The `crossing()` function ensures that we get all possible combinations of the two datasets. After combining, we select only the `gvkey` and `year` columns for our final yearly panel.

Next, we construct the `stock_panel_monthly` panel. Similar to the yearly panel, we use the `crossing()` function to combine `stock_identifiers` with a new dataset that has the `month` variable from `time_series_months`. After merging, we select the columns `permno`, `gvkey`, `month`, `siccd`, `industry`, `exchcd`, and `exchange` to form our monthly panel.

Lastly, we create the `stock_panel_daily` panel. We combine `stock_identifiers` with a dataset containing the `date` variable from `time_series_days`. After merging, we retain only the `permno` and `date` columns for our daily panel.

```{r}
stock_panel_yearly <- crossing(
  stock_identifiers, 
  tibble(year = time_series_years)
) |> 
  select(gvkey, year)

stock_panel_monthly <- crossing(
  stock_identifiers, 
  tibble(month = time_series_months)
) |> 
  select(permno, gvkey, month, siccd, industry, exchcd, exchange)

stock_panel_daily <- crossing(
  stock_identifiers, 
  tibble(date = time_series_days)
)|> 
  select(permno, date)
```

In this code chunk, we simulate and structure a beta table for stocks, and subsequently write this simulated data to a database. We first extract the "beta" table from the `tidy_finance` dataset using the `tbl()` function. From this table, we compute the mean of the `beta_monthly` column using the `summarize()` function. This gives us an idea of the average monthly beta value in our original dataset.

We then proceed to simulate beta values for our `stock_panel_monthly` dataset. We generate simulated monthly beta values (`beta_monthly`) using the `rnorm()` function. This function generates random numbers from a normal distribution. We specify the number of values to generate using `n()`, set the mean to 1.1, and the standard deviation to 0.71. For daily beta values (`beta_daily`), we take the simulated monthly beta and add a small random noise to it. This noise is generated again using the `rnorm()` function, but this time we divide the random values by 100 to ensure they are small deviations from the monthly beta.

```{r}
## Simulate beta table
tbl(tidy_finance, "beta") |> 
  summarize(mean(beta_monthly), sd(beta_monthly))

beta_dummy <- stock_panel_monthly |> 
  mutate(
    beta_monthly = rnorm(n(), mean = 1.1, sd = 0.71),
    beta_daily = beta_monthly + rnorm(n()) / 100
  )

dbWriteTable(tidy_finance_dummy, "beta", 
             beta_dummy, overwrite = TRUE)
```


```{r}
## Create compustat dummy data
tbl(tidy_finance, "compustat")

relevant_columns <- tbl(tidy_finance, "compustat") |> 
  select(-c(gvkey, datadate, year)) |> 
  names()

commands <- unlist(
  map(
    relevant_columns, 
    ~rlang::exprs(!!..1 := runif(n()))
  )
)

compustat_dummy <- stock_panel_yearly |> 
  mutate(
    datadate = ymd(str_c(year, "12", "31")),
    !!!commands
  )

dbWriteTable(tidy_finance_dummy, "compustat", 
             compustat_dummy, overwrite = TRUE)
```


```{r}
## Create crsp_monthly dummy data
tbl(tidy_finance, "crsp_monthly")

crsp_monthly_dummy <- stock_panel_monthly |> 
  mutate(
    date = ceiling_date(month, "month") - 1,
    ret = pmax(rnorm(n()), -1),
    ret_excess = pmax(ret - runif(n(), 0, 0.0025), -1),
    shrout = runif(n(), 1, 50) * 1000,
    altprc = runif(n(), 0, 1000),
    mktcap = shrout * altprc
  ) |> 
  group_by(permno) |> 
  arrange(month) |> 
  mutate(mktcap_lag = lag(mktcap)) |> 
  ungroup()

dbWriteTable(tidy_finance_dummy, "crsp_monthly", 
             crsp_monthly_dummy, overwrite = TRUE)
```


```{r}
## Create crsp_daily dummy data
tbl(tidy_finance, "crsp_daily")

crsp_daily_dummy <- stock_panel_daily |> 
  mutate(
    month = floor_date(date, "month"),
    ret_excess = pmax(rnorm(n()), -1)
  )

dbWriteTable(tidy_finance_dummy, "crsp_daily", 
             crsp_daily_dummy, overwrite = TRUE)

tbl(tidy_finance_dummy, "crsp_daily")
```

## Create bond dummy data

```{r}
number_of_bonds <- 100

## Create mergent dummy data
mergent <- tbl(tidy_finance, "mergent") |> 
  collect()

maturities <- mergent |> 
  count(days = maturity - offering_date) |> 
  mutate(probability = n / sum(n))

amounts <- mergent |> 
  count(offering_amt) |> 
  mutate(probability = n / sum(n))

frequencies <- mergent |> 
  count(interest_frequency) |> 
  mutate(probability = n / sum(n))

coupons <- mergent |> 
  count(coupon) |> 
  mutate(probability = n / sum(n))

sic <- mergent |> 
  count(sic_code) |> 
  mutate(probability = n / sum(n))

mergent_dummy <- 1:number_of_bonds |> 
  map_df(
    function(x) {
      tibble(
        complete_cusip = str_to_upper(
          str_c(
            sample(c(letters, 0:9), 12, replace = TRUE), 
            collapse = ""
          )
        ),
      )
    }
  ) |> 
  mutate(
    maturity = sample(time_series_days, n(), replace = TRUE),
    offering_amt = sample(
      amounts$offering_amt, n(), 
      prob = amounts$probability, 
      replace = TRUE
    ),
    offering_date = maturity - sample(
      maturities$days, n(),
      prob = maturities$probability, 
      replace = TRUE
    ),
    dated_date = offering_date - sample(-10:10, n(), replace = TRUE),
    interest_frequency = sample(
      frequencies$interest_frequency, n(), 
      prob = frequencies$probability, 
      replace = TRUE
    ),
    coupon = sample(
      coupons$coupon, n(), 
      prob = coupons$probability, 
      replace = TRUE
    ),
    last_interest_date = pmax(maturity, offering_date, dated_date),
    issue_id = row_number(),
    issuer_id = sample(1:250, n(), replace = TRUE),
    sic_code = sample(
      sic$sic_code, n(), 
      prob = sic$probability, 
      replace = TRUE
    )
  )
  
dbWriteTable(tidy_finance_dummy, "mergent", 
             mergent_dummy, overwrite = TRUE)
```


```{r}
## Create trace_enhanced dummy data
start_date <- as.Date("2014-01-01")
end_date <- as.Date("2016-11-30")

bonds_panel <- crossing(
  mergent_dummy |> 
    select(cusip_id = complete_cusip),
  tibble(
    trd_exctn_dt = seq(start_date, end_date, "1 day")
  )
)

trace_enhanced_dummy <- bind_rows(
  bonds_panel, bonds_panel, 
  bonds_panel, bonds_panel, 
  bonds_panel) |> 
  mutate(
    trd_exctn_tm = str_c(
      sample(0:24, n(), replace = TRUE), ":", 
      sample(0:60, n(), replace = TRUE), ":", 
      sample(0:60, n(), replace = TRUE)
    ),
    rptd_pr = runif(n(), 10, 200),
    entrd_vol_qt = sample(1:20, n(), replace = TRUE) * 1000,
    yld_pt = runif(n(), -10, 10),
    rpt_side_cd = sample(c("B", "S"), n(), replace = TRUE),
    cntra_mp_id = sample(c("C", "D"), n(), replace = TRUE)
  )
  
dbWriteTable(tidy_finance_dummy, "trace_enhanced", 
             trace_enhanced_dummy, overwrite = TRUE)
```

```{r}
dbSendQuery(tidy_finance_dummy, "VACUUM;")
```

